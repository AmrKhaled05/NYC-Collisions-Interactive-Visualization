{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1045fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:47.522468Z",
     "start_time": "2025-11-21T15:43:47.520182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8d543b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:53.471121Z",
     "start_time": "2025-11-21T15:43:47.538959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Crashes sample loaded: (2219657, 29)\n",
      "\n",
      "=== DATASET STRUCTURE OVERVIEW ===\n",
      "Crashes Dataset: 29 columns\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "crashes_file = r'data\\Motor_Vehicle_Collisions_Crashes.csv'\n",
    "persons_file = r'data\\Motor_Vehicle_Collisions_Person.csv'\n",
    "\n",
    "# Load sample from crashes dataset\n",
    "crashes_sample = pd.read_csv(crashes_file, low_memory=False)\n",
    "print(f\"âœ“ Crashes sample loaded: {crashes_sample.shape}\")\n",
    "\n",
    "print(\"\\n=== DATASET STRUCTURE OVERVIEW ===\")\n",
    "print(f\"Crashes Dataset: {crashes_sample.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a237bb",
   "metadata": {},
   "source": [
    "## Dataset 1: Motor Vehicle Collisions - Crashes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bd6de4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:54.104485Z",
     "start_time": "2025-11-21T15:43:54.096578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Crashes Sample ---\n",
      "   CRASH DATE CRASH TIME   BOROUGH ZIP CODE  LATITUDE  LONGITUDE                    LOCATION           ON STREET NAME CROSS STREET NAME OFF STREET NAME  NUMBER OF PERSONS INJURED  NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  NUMBER OF MOTORIST KILLED CONTRIBUTING FACTOR VEHICLE 1 CONTRIBUTING FACTOR VEHICLE 2 CONTRIBUTING FACTOR VEHICLE 3 CONTRIBUTING FACTOR VEHICLE 4 CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID                  VEHICLE TYPE CODE 1 VEHICLE TYPE CODE 2 VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5\n",
      "0  09/11/2021       2:39       NaN      NaN       NaN        NaN                         NaN    WHITESTONE EXPRESSWAY         20 AVENUE             NaN                        2.0                       0.0                              0                             0                          0                         0                           2                          0  Aggressive Driving/Road Rage                   Unspecified                           NaN                           NaN                           NaN       4455765                                Sedan               Sedan                 NaN                 NaN                 NaN\n",
      "1  03/26/2022      11:45       NaN      NaN       NaN        NaN                         NaN  QUEENSBORO BRIDGE UPPER               NaN             NaN                        1.0                       0.0                              0                             0                          0                         0                           1                          0             Pavement Slippery                           NaN                           NaN                           NaN                           NaN       4513547                                Sedan                 NaN                 NaN                 NaN                 NaN\n",
      "2  11/01/2023       1:29  BROOKLYN    11230  40.62179 -73.970024      (40.62179, -73.970024)            OCEAN PARKWAY          AVENUE K             NaN                        1.0                       0.0                              0                             0                          0                         0                           1                          0                   Unspecified                   Unspecified                   Unspecified                           NaN                           NaN       4675373                                Moped               Sedan               Sedan                 NaN                 NaN\n",
      "3  06/29/2022       6:55       NaN      NaN       NaN        NaN                         NaN       THROGS NECK BRIDGE               NaN             NaN                        0.0                       0.0                              0                             0                          0                         0                           0                          0         Following Too Closely                   Unspecified                           NaN                           NaN                           NaN       4541903                                Sedan       Pick-up Truck                 NaN                 NaN                 NaN\n",
      "4  09/21/2022      13:21       NaN      NaN       NaN        NaN                         NaN          BROOKLYN BRIDGE               NaN             NaN                        0.0                       0.0                              0                             0                          0                         0                           0                          0           Passing Too Closely                   Unspecified                           NaN                           NaN                           NaN       4566131  Station Wagon/Sport Utility Vehicle                 NaN                 NaN                 NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of each dataset\n",
    "print(\"\\n--- Crashes Sample ---\")\n",
    "print(crashes_sample.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0aed81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:55.664626Z",
     "start_time": "2025-11-21T15:43:54.197571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\n",
      "==================================================\n",
      "\n",
      "All columns with their missing value statistics:\n",
      "                       Column  Missing_Count  Missing_Percentage Data_Type\n",
      "          VEHICLE TYPE CODE 5        2209932               99.56    object\n",
      "CONTRIBUTING FACTOR VEHICLE 5        2209616               99.55    object\n",
      "          VEHICLE TYPE CODE 4        2184322               98.41    object\n",
      "CONTRIBUTING FACTOR VEHICLE 4        2182991               98.35    object\n",
      "          VEHICLE TYPE CODE 3        2065294               93.05    object\n",
      "CONTRIBUTING FACTOR VEHICLE 3        2059062               92.76    object\n",
      "              OFF STREET NAME        1828634               82.38    object\n",
      "            CROSS STREET NAME         848140               38.21    object\n",
      "                     ZIP CODE         680402               30.65    object\n",
      "                      BOROUGH         680127               30.64    object\n",
      "               ON STREET NAME         483397               21.78    object\n",
      "          VEHICLE TYPE CODE 2         445154               20.06    object\n",
      "CONTRIBUTING FACTOR VEHICLE 2         356262               16.05    object\n",
      "                     LOCATION         240346               10.83    object\n",
      "                     LATITUDE         240346               10.83   float64\n",
      "                    LONGITUDE         240346               10.83   float64\n",
      "          VEHICLE TYPE CODE 1          16146                0.73    object\n",
      "CONTRIBUTING FACTOR VEHICLE 1           7837                0.35    object\n",
      "     NUMBER OF PERSONS KILLED             31                0.00   float64\n",
      "    NUMBER OF PERSONS INJURED             18                0.00   float64\n",
      "                   CRASH DATE              0                0.00    object\n",
      "NUMBER OF PEDESTRIANS INJURED              0                0.00     int64\n",
      "                   CRASH TIME              0                0.00    object\n",
      "    NUMBER OF MOTORIST KILLED              0                0.00     int64\n",
      "   NUMBER OF MOTORIST INJURED              0                0.00     int64\n",
      " NUMBER OF PEDESTRIANS KILLED              0                0.00     int64\n",
      "    NUMBER OF CYCLIST INJURED              0                0.00     int64\n",
      "     NUMBER OF CYCLIST KILLED              0                0.00     int64\n",
      "                 COLLISION_ID              0                0.00     int64\n"
     ]
    }
   ],
   "source": [
    "# Clear any previous output and create missing stats analysis\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': crashes_sample.columns,\n",
    "    'Missing_Count': crashes_sample.isnull().sum(),\n",
    "    'Missing_Percentage': (crashes_sample.isnull().sum() / len(crashes_sample) * 100).round(2),\n",
    "    'Data_Type': crashes_sample.dtypes\n",
    "})\n",
    "\n",
    "# Sort by missing count (descending)\n",
    "missing_stats = missing_stats.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Missing Values Analysis for Crashes Dataset\n",
    "print(\"ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAll columns with their missing value statistics:\")\n",
    "print(missing_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfccd1",
   "metadata": {},
   "source": [
    "Location, Latitude, Longitude are coordinates and will provide significant insights, they are in sync of missing values, we should inspect them fruther below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c60909",
   "metadata": {},
   "source": [
    "### Location Data Completeness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b51e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:55.965133Z",
     "start_time": "2025-11-21T15:43:55.686979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ºï¸ LOCATION DATA COMPLETENESS ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "1. Rows with AT LEAST ONE location field filled:\n",
      "   â€¢ Count: 2,189,634 rows (98.65%)\n",
      "\n",
      "2. Rows with ALL location fields empty:\n",
      "   â€¢ Count: 30,023 rows (1.35%)\n"
     ]
    }
   ],
   "source": [
    "# Location Data Completeness Analysis\n",
    "# Define all location columns to analyze (Including LATITUDE, LONGITUDE, LOCATION)\n",
    "location_cols = ['BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME']\n",
    "\n",
    "# 1. Rows with at least ONE location field filled\n",
    "at_least_one_mask = False\n",
    "for col in location_cols:\n",
    "    at_least_one_mask = at_least_one_mask | crashes_sample[col].notna()\n",
    "\n",
    "at_least_one_count = at_least_one_mask.sum()\n",
    "\n",
    "# 2. Rows with ALL location fields empty\n",
    "all_empty_count = len(crashes_sample) - at_least_one_count\n",
    "\n",
    "# Now print all results at once\n",
    "print(\"ðŸ—ºï¸ LOCATION DATA COMPLETENESS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Rows with AT LEAST ONE location field filled:\")\n",
    "print(f\"   â€¢ Count: {at_least_one_count:,} rows ({at_least_one_count/len(crashes_sample)*100:.2f}%)\")\n",
    "print(f\"\\n2. Rows with ALL location fields empty:\")\n",
    "print(f\"   â€¢ Count: {all_empty_count:,} rows ({all_empty_count/len(crashes_sample)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96e424",
   "metadata": {},
   "source": [
    "since the 2. Rows with ALL location fields empty:\n",
    "   â€¢ Count: 30,023 rows (1.35%)\n",
    "   then the data provides no geographical meaning and can't be properly imputated\n",
    "it is resonable to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad27b8ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:43:56.535541Z",
     "start_time": "2025-11-21T15:43:55.970095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ After dropping rows with all location fields empty: (2189634, 29)\n",
      "Percentage of rows retained: 98.65%\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with all location fields empty\n",
    "original_shape = crashes_sample.shape\n",
    "crashes_sample = crashes_sample[at_least_one_mask].reset_index(drop=True)\n",
    "print(f\"\\nâœ“ After dropping rows with all location fields empty: {crashes_sample.shape}\")\n",
    "print(f\"Percentage of rows retained: {len(crashes_sample)/ original_shape[0] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a0b39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:23.563516Z",
     "start_time": "2025-11-21T15:43:56.540519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” LONGITUDE/LATITUDE vs LOCATION COORDINATE CONSISTENCY CHECK\n",
      "======================================================================\n",
      "Rows with LONGITUDE, LATITUDE, and LOCATION all present: 1,979,311\n",
      "Rows where LAT/LON/LOCATION either all missing or all filled: 2,189,634 (100.00%)\n",
      "Rows where LATITUDE is 0: 6,495\n",
      "\n",
      "\n",
      "Successfully extracted coordinates from LOCATION: 1,979,311\n",
      "\n",
      "ðŸ“Š COORDINATE MATCHING RESULTS:\n",
      "   â€¢ LONGITUDE matches: 1,979,311 / 1,979,311 (100.00%)\n",
      "   â€¢ LATITUDE matches: 1,979,311 / 1,979,311 (100.00%)\n",
      "   â€¢ BOTH coordinates match: 1,979,311 / 1,979,311 (100.00%)\n",
      "\n",
      "âœ… PERFECT MATCH: All coordinates are 100% consistent!\n"
     ]
    }
   ],
   "source": [
    "# Get rows where all three fields exist\n",
    "all_coords_exist = crashes_sample['LONGITUDE'].notna() & crashes_sample['LATITUDE'].notna() & crashes_sample['LOCATION'].notna()\n",
    "all_coords_count = all_coords_exist.sum()\n",
    "\n",
    "# Check rows where LATITUDE, LONGITUDE, and LOCATION either all missing or all filled\n",
    "lat_lon_loc_mask = (crashes_sample['LATITUDE'].isna() & crashes_sample['LONGITUDE'].isna() & crashes_sample['LOCATION'].isna()) | \\\n",
    "                   (crashes_sample['LATITUDE'].notna() & crashes_sample['LONGITUDE'].notna() & crashes_sample['LOCATION'].notna())\n",
    "lat_lon_loc_count = lat_lon_loc_mask.sum()\n",
    "\n",
    "# Initialize variables\n",
    "successful_extractions = 0\n",
    "long_match = 0\n",
    "lat_match = 0\n",
    "both_match = 0\n",
    "coords_subset = None\n",
    "\n",
    "if all_coords_count > 0:\n",
    "    # Work with subset that has all coordinates\n",
    "    coords_subset = crashes_sample[all_coords_exist].copy()\n",
    "    \n",
    "    # Extract coordinates from LOCATION field using string splitting\n",
    "    # Note: LOCATION format is (LATITUDE, LONGITUDE) not (LONGITUDE, LATITUDE)\n",
    "    def extract_coords(location_str):\n",
    "        try:\n",
    "            # Remove spaces and parentheses, then split by comma\n",
    "            trimmed = str(location_str).strip().strip('()')\n",
    "            parts = trimmed.split(',')\n",
    "            if len(parts) == 2:\n",
    "                latitude = float(parts[0].strip())   # First value is LATITUDE\n",
    "                longitude = float(parts[1].strip())  # Second value is LONGITUDE\n",
    "                return longitude, latitude\n",
    "            else:\n",
    "                return None, None\n",
    "        except:\n",
    "            return None, None\n",
    "    \n",
    "    # Apply extraction function\n",
    "    coords_subset[['LOC_LONG', 'LOC_LAT']] = coords_subset['LOCATION'].apply(\n",
    "        lambda x: pd.Series(extract_coords(x))\n",
    "    )\n",
    "    \n",
    "    # Count successful extractions\n",
    "    successful_extractions = coords_subset['LOC_LONG'].notna().sum()\n",
    "    \n",
    "    if successful_extractions > 0:\n",
    "        # Compare coordinates (check for exact matches)\n",
    "        long_match = (coords_subset['LONGITUDE'] == coords_subset['LOC_LONG']).sum()\n",
    "        lat_match = (coords_subset['LATITUDE'] == coords_subset['LOC_LAT']).sum()\n",
    "        both_match = ((coords_subset['LONGITUDE'] == coords_subset['LOC_LONG']) & \n",
    "                     (coords_subset['LATITUDE'] == coords_subset['LOC_LAT'])).sum()\n",
    "        \n",
    "\n",
    "# Check consistency between LONGITUDE/LATITUDE and LOCATION coordinates\n",
    "print(\"ðŸ” LONGITUDE/LATITUDE vs LOCATION COORDINATE CONSISTENCY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Print all results at the end\n",
    "print(f\"Rows with LONGITUDE, LATITUDE, and LOCATION all present: {all_coords_count:,}\")\n",
    "print(f\"Rows where LAT/LON/LOCATION either all missing or all filled: {lat_lon_loc_count:,} ({lat_lon_loc_count/len(crashes_sample)*100:.2f}%)\")\n",
    "# Count Rows where LATITUDE == \"0\"\n",
    "print(f\"Rows where LATITUDE is 0: {(crashes_sample['LATITUDE'] == 0).sum():,}\")\n",
    "\n",
    "if all_coords_count > 0:\n",
    "    print(f\"\\n\\nSuccessfully extracted coordinates from LOCATION: {successful_extractions:,}\")\n",
    "    \n",
    "    if successful_extractions > 0:\n",
    "        print(f\"\\nðŸ“Š COORDINATE MATCHING RESULTS:\")\n",
    "        print(f\"   â€¢ LONGITUDE matches: {long_match:,} / {successful_extractions:,} ({long_match/successful_extractions*100:.2f}%)\")\n",
    "        print(f\"   â€¢ LATITUDE matches: {lat_match:,} / {successful_extractions:,} ({lat_match/successful_extractions*100:.2f}%)\")\n",
    "        print(f\"   â€¢ BOTH coordinates match: {both_match:,} / {successful_extractions:,} ({both_match/successful_extractions*100:.2f}%)\")\n",
    "        \n",
    "        if both_match == successful_extractions:\n",
    "            print(f\"\\nâœ… PERFECT MATCH: All coordinates are 100% consistent!\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ MISMATCHES FOUND: {successful_extractions - both_match:,} rows with inconsistent coordinates\")\n",
    "            \n",
    "            # Show mismatch examples\n",
    "            mismatch_mask = ((coords_subset['LONGITUDE'] != coords_subset['LOC_LONG']) | \n",
    "                           (coords_subset['LATITUDE'] != coords_subset['LOC_LAT']))\n",
    "            mismatch_rows = coords_subset[mismatch_mask]\n",
    "            \n",
    "            print(f\"\\nðŸ“‹ FIRST 10 MISMATCH EXAMPLES:\")\n",
    "            print(\"-\" * 100)\n",
    "            display_cols = ['COLLISION_ID', 'LONGITUDE', 'LATITUDE', 'LOC_LONG', 'LOC_LAT', 'LOCATION']\n",
    "            print(mismatch_rows[display_cols].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a284b",
   "metadata": {},
   "source": [
    "Results show that the location is redundent due to it is always equivelent to the longitude and latitude\n",
    "and there are 6,495 where latitude and longitude are (0,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4885cb15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:23.986459Z",
     "start_time": "2025-11-21T15:45:23.629203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ºï¸ LOCATION DATA COMPLETENESS ANALYSIS - WITHOUT COORDINATES\n",
      "======================================================================\n",
      "\n",
      "1. Rows with AT LEAST ONE location field filled (no coordinates):\n",
      "   â€¢ Count: 2,128,179 rows (97.19%)\n",
      "\n",
      "2. Rows with ALL location fields empty (no coordinates):\n",
      "   â€¢ Count: 61,455 rows (2.81%)\n",
      "\n",
      "ðŸ“Š COMPARISON:\n",
      "   â€¢ With coordinates: 2,189,634 rows (100.00%)\n",
      "   â€¢ Without coordinates: 2,128,179 rows (97.19%)\n",
      "   â€¢ Difference: 61,455 rows\n",
      "\n",
      "3. Rows with at least ONE street name field filled (On, Cross, Off):\n",
      "   â€¢ Count: 2,127,585 rows (97.17%)\n"
     ]
    }
   ],
   "source": [
    "# Location Data Completeness Analysis - WITHOUT Coordinates/Location\n",
    "\n",
    "# Define location columns excluding LATITUDE, LONGITUDE, LOCATION\n",
    "location_cols_no_coords = ['BOROUGH', 'ZIP CODE', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME']\n",
    "\n",
    "# 1. Rows with at least ONE location field filled (excluding coordinates)\n",
    "at_least_one_mask_no_coords = False\n",
    "for col in location_cols_no_coords:\n",
    "    at_least_one_mask_no_coords = at_least_one_mask_no_coords | crashes_sample[col].notna()\n",
    "\n",
    "at_least_one_count_no_coords = at_least_one_mask_no_coords.sum()\n",
    "\n",
    "# 2. Rows with ALL location fields empty (excluding coordinates)\n",
    "all_empty_count_no_coords = len(crashes_sample) - at_least_one_count_no_coords\n",
    "\n",
    "# 3. Rows with Any street name (On Street OR Cross Street OR Off Street)\n",
    "any_street_cols = ['ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME']\n",
    "any_street_mask = False\n",
    "for col in any_street_cols:\n",
    "    any_street_mask = any_street_mask | crashes_sample[col].notna()\n",
    "any_street_count = any_street_mask.sum()\n",
    "\n",
    "\n",
    "\n",
    "# NOW PRINT EVERYTHING AT ONCE\n",
    "print(\"ðŸ—ºï¸ LOCATION DATA COMPLETENESS ANALYSIS - WITHOUT COORDINATES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n1. Rows with AT LEAST ONE location field filled (no coordinates):\")\n",
    "print(f\"   â€¢ Count: {at_least_one_count_no_coords:,} rows ({at_least_one_count_no_coords/len(crashes_sample)*100:.2f}%)\")\n",
    "print(f\"\\n2. Rows with ALL location fields empty (no coordinates):\")\n",
    "print(f\"   â€¢ Count: {all_empty_count_no_coords:,} rows ({all_empty_count_no_coords/len(crashes_sample)*100:.2f}%)\")\n",
    "print(f\"\\nðŸ“Š COMPARISON:\")\n",
    "print(f\"   â€¢ With coordinates: {at_least_one_count:,} rows ({at_least_one_count/len(crashes_sample)*100:.2f}%)\")\n",
    "print(f\"   â€¢ Without coordinates: {at_least_one_count_no_coords:,} rows ({at_least_one_count_no_coords/len(crashes_sample)*100:.2f}%)\")\n",
    "print(f\"   â€¢ Difference: {at_least_one_count - at_least_one_count_no_coords:,} rows\")\n",
    "print(f\"\\n3. Rows with at least ONE street name field filled (On, Cross, Off):\")\n",
    "print(f\"   â€¢ Count: {any_street_count:,} rows ({any_street_count/len(crashes_sample)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbcd6a",
   "metadata": {},
   "source": [
    "since coordinates are the smallest unit it is hard to impute it by correlation, besides imputing it by central tendancy is not descriptive and will make a change in skewness(around 3% of values change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8e907f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:25.089547Z",
     "start_time": "2025-11-21T15:45:23.991267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ CLEANING INVALID COORDINATES & DETECTING ANOMALIES\n",
      "======================================================================\n",
      "Original dataset shape: (2189634, 29)\n",
      "\n",
      "âœ“ Removed 210,323 rows with all coordinates missing\n",
      "   Shape after removal: (1979311, 29)\n",
      "\n",
      "âœ“ Removed 6,495 rows with coordinates = (0, 0)\n",
      "   Shape after removal: (1972816, 29)\n"
     ]
    }
   ],
   "source": [
    "# Clean invalid coordinates and check for location anomalies\n",
    "print(\"ðŸ§¹ CLEANING INVALID COORDINATES & DETECTING ANOMALIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store original shape for comparison\n",
    "original_shape = crashes_sample.shape\n",
    "print(f\"Original dataset shape: {original_shape}\")\n",
    "\n",
    "# 1. Remove rows with missing coordinates (LATITUDE, LONGITUDE, LOCATION all missing)\n",
    "coords_missing_mask = crashes_sample['LATITUDE'].isna() & crashes_sample['LONGITUDE'].isna() & crashes_sample['LOCATION'].isna()\n",
    "coords_missing_count = coords_missing_mask.sum()\n",
    "\n",
    "crashes_sample = crashes_sample[~coords_missing_mask].reset_index(drop=True)\n",
    "print(f\"\\nâœ“ Removed {coords_missing_count:,} rows with all coordinates missing\")\n",
    "print(f\"   Shape after removal: {crashes_sample.shape}\")\n",
    "\n",
    "# 2. Remove rows with coordinates = (0, 0) - invalid location\n",
    "zero_coords_mask = (crashes_sample['LATITUDE'] == 0) & (crashes_sample['LONGITUDE'] == 0)\n",
    "zero_coords_count = zero_coords_mask.sum()\n",
    "\n",
    "crashes_sample = crashes_sample[~zero_coords_mask].reset_index(drop=True)\n",
    "print(f\"\\nâœ“ Removed {zero_coords_count:,} rows with coordinates = (0, 0)\")\n",
    "print(f\"   Shape after removal: {crashes_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7f7e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:26.567368Z",
     "start_time": "2025-11-21T15:45:25.140630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” COORDINATE ANOMALY DETECTION\n",
      "--------------------------------------------------\n",
      "ðŸ“Š COORDINATE STATISTICS:\n",
      "   â€¢ Total rows with coordinates: 1,972,816\n",
      "   â€¢ Latitude range: 30.784180 to 43.344444\n",
      "   â€¢ Longitude range: -201.359990 to -32.768513\n",
      "\n",
      "ðŸš¨ ANOMALY DETECTION RESULTS:\n",
      "   â€¢ Coordinates outside NYC bounds: 150 rows (0.01%)\n",
      "   â€¢ Invalid coordinate outliers: 106 rows\n",
      "   â€¢ Exact duplicate coordinates: 1,782,376 rows at 143,177 unique locations\n",
      "\n",
      "ðŸ“‹ COORDINATES OUTSIDE NYC (first 10):\n",
      " COLLISION_ID  LATITUDE   LONGITUDE  BOROUGH                   ON STREET NAME\n",
      "      3885895 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3975700 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3965268 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3958909 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3968897 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3927302 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3931007 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3922984 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3938631 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3926553 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3929785 40.560600  -74.742000      NaN WEST SHORE EXPRESSWAY           \n",
      "      3918430 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3909853 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3907486 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3909860 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3913499 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3906922 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3900531 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3901582 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3890362 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3886746 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3900738 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3890439 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3873494 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3882083 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3878522 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3877672 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3856097 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      4025636 41.124210  -73.714120      NaN                              NaN\n",
      "      3870246 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3861844 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3828137 40.560600  -74.742000      NaN                              NaN\n",
      "      3833107 40.560600  -74.742000      NaN                              NaN\n",
      "      3849177 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3836227 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3827479 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3825619 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3832438 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3829655 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3822610 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3829449 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3828824 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3826894 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3807804 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3803015 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3798036 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3793823 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3790297 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3793790 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3795169 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3790240 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3777311 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3773254 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3768019 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3772990 40.556175  -47.209625      NaN WEST SHORE EXPRESSWAY           \n",
      "      3766427 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3770138 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3748726 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3748053 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3758066 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3737295 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3744316 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3744329 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3734169 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3728439 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3728412 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3719800 41.126150  -73.713530 BROOKLYN                              NaN\n",
      "      3718980 41.126150  -73.713530      NaN                              NaN\n",
      "      4024533 41.126150  -73.713530      NaN                              NaN\n",
      "      3714669 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3719109 41.126150  -73.713530 BROOKLYN                              NaN\n",
      "      3710587 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3708654 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3710676 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3717295 41.126150  -73.713530      NaN                              NaN\n",
      "      3705394 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3712013 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3688891 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3698752 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3701906 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3690234 40.560600  -74.742000      NaN WEST SHORE EXPRESSWAY           \n",
      "      3694155 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3701559 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3680712 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3677762 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3676160 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3681675 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3680090 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3684094 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3680089 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3680199 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3677759 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3672775 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3665524 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3667901 40.560600  -74.742000      NaN WEST SHORE EXPRESSWAY           \n",
      "      3666689 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3661987 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3666698 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3672194 40.556175  -47.209625      NaN WEST SHORE EXPRESSWAY           \n",
      "      3660895 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3604794 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3650240 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3650157 40.560600  -74.742000      NaN WEST SHORE EXPRESSWAY           \n",
      "      3648623 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3635223 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3628215 40.560600  -74.742000      NaN WEST SHORE EXPRESSWAY           \n",
      "      3631319 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3625037 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3626730 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3625066 40.556175  -47.209625      NaN WEST SHORE EXPRESSWAY           \n",
      "      3616997 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3620481 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3612004 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3616653 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3607165 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3600097 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3594964 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3588925 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3591823 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3584895 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3582426 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3582956 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3575425 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3585773 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3587702 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3580130 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3581787 40.854286 -201.359990      NaN HUTCHINSON RIVER PARKWAY        \n",
      "      3557224 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3579536 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3557202 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3549567 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3550908 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3543148 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3535114 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3726915 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3457736 42.318317  -73.755936      NaN Foot Bridge Ext                 \n",
      "      3455788 42.107204  -76.021630      NaN S Avenue B                      \n",
      "      3446643 40.665226  -32.768513      NaN NASSAU EXPRESSWAY               \n",
      "      3442931 43.344444  -76.263400      NaN Island Rd                       \n",
      "      3442139 40.739876  -73.663010      NaN Dyckman Ave                     \n",
      "      3443941 42.641540  -79.001830      NaN Gowans Rd                       \n",
      "      3445552 30.784180  -89.135270      NaN E Off Ramp                      \n",
      "      3423014 41.061634  -73.970660      NaN Van Wyck Rd                     \n",
      "      3432967 34.783634  -86.768470      NaN                              NaN\n",
      "      3428278 41.061634  -73.970660      NaN Van Wyck Rd                     \n",
      "      3414001 41.258785  -73.990240      NaN Deegan Ln                       \n",
      "      3425492 41.347960  -73.969650      NaN Lower Level                     \n",
      "      3408508 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "      3414570 41.916610  -79.619550      NaN 6th Street Ext                  \n",
      "      3408461 40.758370 -201.237060      NaN QUEENSBORO BRIDGE UPPER ROADWAY \n",
      "\n",
      "ðŸ“‹ COORDINATE OUTLIERS:\n",
      " COLLISION_ID  LATITUDE  LONGITUDE BOROUGH\n",
      "      3885895 40.758370 -201.23706     NaN\n",
      "      3975700 40.758370 -201.23706     NaN\n",
      "      3965268 40.758370 -201.23706     NaN\n",
      "      3958909 40.758370 -201.23706     NaN\n",
      "      3931007 40.758370 -201.23706     NaN\n",
      "      3922984 40.758370 -201.23706     NaN\n",
      "      3938631 40.758370 -201.23706     NaN\n",
      "      3926553 40.758370 -201.23706     NaN\n",
      "      3918430 40.758370 -201.23706     NaN\n",
      "      3909853 40.758370 -201.23706     NaN\n",
      "      3907486 40.758370 -201.23706     NaN\n",
      "      3909860 40.758370 -201.23706     NaN\n",
      "      3913499 40.758370 -201.23706     NaN\n",
      "      3906922 40.758370 -201.23706     NaN\n",
      "      3900531 40.758370 -201.23706     NaN\n",
      "      3901582 40.758370 -201.23706     NaN\n",
      "      3890362 40.758370 -201.23706     NaN\n",
      "      3886746 40.758370 -201.23706     NaN\n",
      "      3900738 40.758370 -201.23706     NaN\n",
      "      3890439 40.758370 -201.23706     NaN\n",
      "      3873494 40.758370 -201.23706     NaN\n",
      "      3882083 40.758370 -201.23706     NaN\n",
      "      3878522 40.758370 -201.23706     NaN\n",
      "      3877672 40.758370 -201.23706     NaN\n",
      "      3856097 40.758370 -201.23706     NaN\n",
      "      3870246 40.758370 -201.23706     NaN\n",
      "      3861844 40.758370 -201.23706     NaN\n",
      "      3849177 40.758370 -201.23706     NaN\n",
      "      3836227 40.758370 -201.23706     NaN\n",
      "      3827479 40.758370 -201.23706     NaN\n",
      "      3825619 40.758370 -201.23706     NaN\n",
      "      3832438 40.758370 -201.23706     NaN\n",
      "      3829655 40.758370 -201.23706     NaN\n",
      "      3822610 40.758370 -201.23706     NaN\n",
      "      3829449 40.758370 -201.23706     NaN\n",
      "      3828824 40.758370 -201.23706     NaN\n",
      "      3826894 40.758370 -201.23706     NaN\n",
      "      3807804 40.758370 -201.23706     NaN\n",
      "      3803015 40.758370 -201.23706     NaN\n",
      "      3798036 40.758370 -201.23706     NaN\n",
      "      3793823 40.758370 -201.23706     NaN\n",
      "      3790297 40.758370 -201.23706     NaN\n",
      "      3793790 40.758370 -201.23706     NaN\n",
      "      3795169 40.758370 -201.23706     NaN\n",
      "      3790240 40.758370 -201.23706     NaN\n",
      "      3773254 40.758370 -201.23706     NaN\n",
      "      3766427 40.758370 -201.23706     NaN\n",
      "      3770138 40.758370 -201.23706     NaN\n",
      "      3758066 40.758370 -201.23706     NaN\n",
      "      3737295 40.758370 -201.23706     NaN\n",
      "      3744316 40.758370 -201.23706     NaN\n",
      "      3744329 40.758370 -201.23706     NaN\n",
      "      3734169 40.758370 -201.23706     NaN\n",
      "      3728439 40.758370 -201.23706     NaN\n",
      "      3728412 40.758370 -201.23706     NaN\n",
      "      3714669 40.758370 -201.23706     NaN\n",
      "      3708654 40.758370 -201.23706     NaN\n",
      "      3710676 40.758370 -201.23706     NaN\n",
      "      3712013 40.758370 -201.23706     NaN\n",
      "      3688891 40.758370 -201.23706     NaN\n",
      "      3698752 40.758370 -201.23706     NaN\n",
      "      3701906 40.758370 -201.23706     NaN\n",
      "      3694155 40.758370 -201.23706     NaN\n",
      "      3680712 40.758370 -201.23706     NaN\n",
      "      3677762 40.758370 -201.23706     NaN\n",
      "      3676160 40.758370 -201.23706     NaN\n",
      "      3681675 40.758370 -201.23706     NaN\n",
      "      3680090 40.758370 -201.23706     NaN\n",
      "      3684094 40.758370 -201.23706     NaN\n",
      "      3680089 40.758370 -201.23706     NaN\n",
      "      3677759 40.758370 -201.23706     NaN\n",
      "      3672775 40.758370 -201.23706     NaN\n",
      "      3665524 40.758370 -201.23706     NaN\n",
      "      3666689 40.758370 -201.23706     NaN\n",
      "      3661987 40.758370 -201.23706     NaN\n",
      "      3666698 40.758370 -201.23706     NaN\n",
      "      3660895 40.758370 -201.23706     NaN\n",
      "      3604794 40.758370 -201.23706     NaN\n",
      "      3650240 40.758370 -201.23706     NaN\n",
      "      3648623 40.758370 -201.23706     NaN\n",
      "      3635223 40.758370 -201.23706     NaN\n",
      "      3631319 40.758370 -201.23706     NaN\n",
      "      3625037 40.758370 -201.23706     NaN\n",
      "      3626730 40.758370 -201.23706     NaN\n",
      "      3616997 40.758370 -201.23706     NaN\n",
      "      3620481 40.758370 -201.23706     NaN\n",
      "      3612004 40.758370 -201.23706     NaN\n",
      "      3607165 40.758370 -201.23706     NaN\n",
      "      3600097 40.758370 -201.23706     NaN\n",
      "      3594964 40.758370 -201.23706     NaN\n",
      "      3591823 40.758370 -201.23706     NaN\n",
      "      3584895 40.758370 -201.23706     NaN\n",
      "      3582426 40.758370 -201.23706     NaN\n",
      "      3575425 40.758370 -201.23706     NaN\n",
      "      3587702 40.758370 -201.23706     NaN\n",
      "      3580130 40.758370 -201.23706     NaN\n",
      "      3581787 40.854286 -201.35999     NaN\n",
      "      3557224 40.758370 -201.23706     NaN\n",
      "      3579536 40.758370 -201.23706     NaN\n",
      "      3557202 40.758370 -201.23706     NaN\n",
      "      3550908 40.758370 -201.23706     NaN\n",
      "      3543148 40.758370 -201.23706     NaN\n",
      "      3535114 40.758370 -201.23706     NaN\n",
      "      3726915 40.758370 -201.23706     NaN\n",
      "      3408508 40.758370 -201.23706     NaN\n",
      "      3408461 40.758370 -201.23706     NaN\n",
      "\n",
      "ðŸ“‹ TOP 5 MOST COMMON DUPLICATE LOCATIONS:\n",
      "   â€¢ (40.608757, -74.038086): 847 crashes - VERRAZANO BRIDGE UPPER           in nan\n",
      "   â€¢ (40.861862, -73.912820): 685 crashes - WEST FORDHAM ROAD in nan\n",
      "   â€¢ (40.696033, -73.984530): 682 crashes - FLATBUSH AVENUE EXTENSION in BROOKLYN\n",
      "   â€¢ (40.804700, -73.912430): 597 crashes - BRUCKNER BOULEVARD in nan\n",
      "   â€¢ (40.696035, -73.984529): 587 crashes - TILLARY STREET in BROOKLYN\n",
      "\n",
      "ðŸ“ˆ CLEANING SUMMARY:\n",
      "   â€¢ Original rows: 2,189,634\n",
      "   â€¢ Removed missing coordinates: 210,323\n",
      "   â€¢ Removed zero coordinates: 6,495\n",
      "   â€¢ Total rows removed: 216,818\n",
      "   â€¢ Final dataset: 1,972,816 rows (90.10% retained)\n",
      "\n",
      "ðŸ’¡ RECOMMENDATION:\n",
      "   â€¢ Consider removing 150 rows outside NYC bounds\n",
      "   â€¢ Consider removing 106 rows with invalid coordinates\n"
     ]
    }
   ],
   "source": [
    "# 3. Check for other coordinate anomalies in remaining data\n",
    "print(f\"\\nðŸ” COORDINATE ANOMALY DETECTION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Get rows with coordinates\n",
    "has_coords = crashes_sample['LATITUDE'].notna() & crashes_sample['LONGITUDE'].notna()\n",
    "coord_data = crashes_sample[has_coords].copy()\n",
    "\n",
    "if len(coord_data) > 0:\n",
    "    # NYC approximate boundaries\n",
    "    NYC_LAT_MIN, NYC_LAT_MAX = 40.4774, 40.9176  # Roughly Staten Island to Bronx\n",
    "    NYC_LON_MIN, NYC_LON_MAX = -74.2591, -73.7004  # Roughly NJ border to Queens\n",
    "    \n",
    "    # Check coordinates outside NYC bounds\n",
    "    outside_nyc = (\n",
    "        (coord_data['LATITUDE'] < NYC_LAT_MIN) | \n",
    "        (coord_data['LATITUDE'] > NYC_LAT_MAX) |\n",
    "        (coord_data['LONGITUDE'] < NYC_LON_MIN) | \n",
    "        (coord_data['LONGITUDE'] > NYC_LON_MAX)\n",
    "    )\n",
    "    outside_nyc_count = outside_nyc.sum()\n",
    "    \n",
    "    # Check for extreme outliers (likely data entry errors)\n",
    "    lat_outliers = (coord_data['LATITUDE'].abs() > 90) | (coord_data['LATITUDE'] == 0)\n",
    "    lon_outliers = (coord_data['LONGITUDE'].abs() > 180) | (coord_data['LONGITUDE'] == 0)\n",
    "    coord_outliers = lat_outliers | lon_outliers\n",
    "    outlier_count = coord_outliers.sum()\n",
    "    \n",
    "    # Check for duplicate coordinates (exact same location)\n",
    "    duplicate_coords = coord_data.duplicated(subset=['LATITUDE', 'LONGITUDE'], keep=False)\n",
    "    duplicate_count = duplicate_coords.sum()\n",
    "    unique_duplicate_locations = coord_data[duplicate_coords].drop_duplicates(subset=['LATITUDE', 'LONGITUDE']).shape[0]\n",
    "    \n",
    "    # Coordinate statistics\n",
    "    print(f\"ðŸ“Š COORDINATE STATISTICS:\")\n",
    "    print(f\"   â€¢ Total rows with coordinates: {len(coord_data):,}\")\n",
    "    print(f\"   â€¢ Latitude range: {coord_data['LATITUDE'].min():.6f} to {coord_data['LATITUDE'].max():.6f}\")\n",
    "    print(f\"   â€¢ Longitude range: {coord_data['LONGITUDE'].min():.6f} to {coord_data['LONGITUDE'].max():.6f}\")\n",
    "    \n",
    "    print(f\"\\nðŸš¨ ANOMALY DETECTION RESULTS:\")\n",
    "    print(f\"   â€¢ Coordinates outside NYC bounds: {outside_nyc_count:,} rows ({outside_nyc_count/len(coord_data)*100:.2f}%)\")\n",
    "    print(f\"   â€¢ Invalid coordinate outliers: {outlier_count:,} rows\")\n",
    "    print(f\"   â€¢ Exact duplicate coordinates: {duplicate_count:,} rows at {unique_duplicate_locations:,} unique locations\")\n",
    "    \n",
    "    # Show examples of anomalies\n",
    "    if outside_nyc_count > 0:\n",
    "        print(f\"\\nðŸ“‹ COORDINATES OUTSIDE NYC (first 10):\")\n",
    "        outside_examples = coord_data[outside_nyc][['COLLISION_ID', 'LATITUDE', 'LONGITUDE', 'BOROUGH', 'ON STREET NAME']]\n",
    "        print(outside_examples.to_string(index=False))\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        print(f\"\\nðŸ“‹ COORDINATE OUTLIERS:\")\n",
    "        outlier_examples = coord_data[coord_outliers][['COLLISION_ID', 'LATITUDE', 'LONGITUDE', 'BOROUGH']]\n",
    "        print(outlier_examples.to_string(index=False))\n",
    "    \n",
    "    # Show most common duplicate locations\n",
    "    if duplicate_count > 0:\n",
    "        print(f\"\\nðŸ“‹ TOP 5 MOST COMMON DUPLICATE LOCATIONS:\")\n",
    "        top_duplicates = coord_data[duplicate_coords].groupby(['LATITUDE', 'LONGITUDE']).size().sort_values(ascending=False).head()\n",
    "        for (lat, lon), count in top_duplicates.items():\n",
    "            example_row = coord_data[(coord_data['LATITUDE'] == lat) & (coord_data['LONGITUDE'] == lon)].iloc[0]\n",
    "            print(f\"   â€¢ ({lat:.6f}, {lon:.6f}): {count:,} crashes - {example_row.get('ON STREET NAME', 'Unknown')} in {example_row.get('BOROUGH', 'Unknown')}\")\n",
    "\n",
    "# Summary of cleaning\n",
    "total_removed = original_shape[0] - crashes_sample.shape[0]\n",
    "print(f\"\\nðŸ“ˆ CLEANING SUMMARY:\")\n",
    "print(f\"   â€¢ Original rows: {original_shape[0]:,}\")\n",
    "print(f\"   â€¢ Removed missing coordinates: {coords_missing_count:,}\")\n",
    "print(f\"   â€¢ Removed zero coordinates: {zero_coords_count:,}\")\n",
    "print(f\"   â€¢ Total rows removed: {total_removed:,}\")\n",
    "print(f\"   â€¢ Final dataset: {crashes_sample.shape[0]:,} rows ({crashes_sample.shape[0]/original_shape[0]*100:.2f}% retained)\")\n",
    "\n",
    "# Ask user what to do with anomalies\n",
    "if len(coord_data) > 0 and (outside_nyc_count > 0 or outlier_count > 0):\n",
    "    print(f\"\\nðŸ’¡ RECOMMENDATION:\")\n",
    "    if outside_nyc_count > 0:\n",
    "        print(f\"   â€¢ Consider removing {outside_nyc_count:,} rows outside NYC bounds\")\n",
    "    if outlier_count > 0:\n",
    "        print(f\"   â€¢ Consider removing {outlier_count:,} rows with invalid coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c4b29",
   "metadata": {},
   "source": [
    "this shows some rows off NYC which is invalid state, and by inspective them there are many locations with same location and diffirent boroughs making it hard to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3022a2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:27.157362Z",
     "start_time": "2025-11-21T15:45:26.646589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Removed rows with coordinates outside NYC bounds. New shape: (1972666, 29)\n"
     ]
    }
   ],
   "source": [
    "# Remove outlier coordinates based on location\n",
    "\n",
    "# Remove rows with coordinates outside NYC bounds\n",
    "crashes_sample = crashes_sample[~outside_nyc].reset_index(drop=True)\n",
    "print(f\"\\nâœ“ Removed rows with coordinates outside NYC bounds. New shape: {crashes_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6d57a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:45:30.058372Z",
     "start_time": "2025-11-21T15:45:27.162443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ TESTING COORDINATE-BASED IMPUTATION FOR BOROUGH & ZIP CODE\n",
      "======================================================================\n",
      "ðŸ“Š MISSING VALUE COUNTS:\n",
      "   â€¢ Missing BOROUGH: 476,174 rows\n",
      "   â€¢ Missing ZIP CODE: 476,419 rows\n",
      "   â€¢ Total rows with coordinates: 1,972,666\n",
      "\n",
      "ðŸ™ï¸ TESTING BOROUGH IMPUTATION:\n",
      "--------------------------------------------------\n",
      "ðŸ“‹ BOROUGH IMPUTATION RESULTS (first 10 examples):\n",
      "\n",
      "1. Collision ID: 4486304\n",
      "   Coordinates: (40.804375, -73.937420)\n",
      "   Predicted Borough: MANHATTAN (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor boroughs: ['MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN']\n",
      "\n",
      "2. Collision ID: 4486581\n",
      "   Coordinates: (40.784615, -73.953964)\n",
      "   Predicted Borough: MANHATTAN (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor boroughs: ['MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN', 'MANHATTAN']\n",
      "\n",
      "3. Collision ID: 4456659\n",
      "   Coordinates: (40.720535, -73.888850)\n",
      "   Predicted Borough: QUEENS (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor boroughs: ['QUEENS', 'QUEENS', 'QUEENS', 'QUEENS', 'QUEENS', 'QUEENS', 'QUEENS', 'QUEENS', 'QUEENS']\n",
      "\n",
      "ðŸ“® TESTING ZIP CODE IMPUTATION:\n",
      "--------------------------------------------------\n",
      "ðŸ“‹ ZIP CODE IMPUTATION RESULTS (first 10 examples):\n",
      "\n",
      "1. Collision ID: 4486304\n",
      "   Coordinates: (40.804375, -73.937420)\n",
      "   Predicted ZIP: 10035 (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor ZIP codes: ['10035', '10035', '10035', '10035', '10035', '10035']\n",
      "\n",
      "2. Collision ID: 4486581\n",
      "   Coordinates: (40.784615, -73.953964)\n",
      "   Predicted ZIP: 10128 (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor ZIP codes: ['10128', '10128', '10128', '10128', '10128', '10128', '10128']\n",
      "\n",
      "3. Collision ID: 4456659\n",
      "   Coordinates: (40.720535, -73.888850)\n",
      "   Predicted ZIP: 11379 (confidence: 1.00)\n",
      "   Average distance to neighbors: 0.000 km\n",
      "   Neighbor ZIP codes: ['11379', '11379', '11379', '11379', '11379', '11379', '11379', '11379', '11379']\n",
      "\n",
      "ðŸ“ˆ IMPUTATION QUALITY ASSESSMENT:\n",
      "--------------------------------------------------\n",
      "BOROUGH Imputation:\n",
      "   â€¢ Average confidence: 1.00\n",
      "   â€¢ Average distance to neighbors: 0.000 km\n",
      "   â€¢ High confidence predictions (>0.6): 3/3\n",
      "\n",
      "ZIP CODE Imputation:\n",
      "   â€¢ Average confidence: 1.00\n",
      "   â€¢ Average distance to neighbors: 0.000 km\n",
      "   â€¢ High confidence predictions (>0.6): 3/3\n",
      "\n",
      "ðŸ’¡ RECOMMENDATIONS:\n",
      "   âœ… BOROUGH imputation looks promising (avg confidence: 1.00)\n",
      "   âœ… ZIP CODE imputation looks promising (avg confidence: 1.00)\n",
      "\n",
      "ðŸš€ NEXT STEPS:\n",
      "   â€¢ If results look good, we can impute all missing values\n",
      "   â€¢ Consider adjusting k=10 neighbors based on confidence scores\n",
      "   â€¢ Set confidence threshold for imputation (e.g., only impute if confidence > 0.6)\n"
     ]
    }
   ],
   "source": [
    "# Test coordinate-based imputation for BOROUGH and ZIP CODE\n",
    "print(\"ðŸŽ¯ TESTING COORDINATE-BASED IMPUTATION FOR BOROUGH & ZIP CODE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Get rows with coordinates\n",
    "has_coords = crashes_sample['LATITUDE'].notna() & crashes_sample['LONGITUDE'].notna()\n",
    "coord_data = crashes_sample[has_coords].copy()\n",
    "\n",
    "# Separate data into known and unknown BOROUGH/ZIP CODE\n",
    "borough_known = coord_data['BOROUGH'].notna()\n",
    "zip_known = coord_data['ZIP CODE'].notna()\n",
    "\n",
    "# Count missing values\n",
    "borough_missing_count = (~borough_known).sum()\n",
    "zip_missing_count = (~zip_known).sum()\n",
    "\n",
    "print(f\"ðŸ“Š MISSING VALUE COUNTS:\")\n",
    "print(f\"   â€¢ Missing BOROUGH: {borough_missing_count:,} rows\")\n",
    "print(f\"   â€¢ Missing ZIP CODE: {zip_missing_count:,} rows\")\n",
    "print(f\"   â€¢ Total rows with coordinates: {len(coord_data):,}\")\n",
    "\n",
    "if borough_missing_count > 0 or zip_missing_count > 0:\n",
    "    # Prepare coordinate arrays\n",
    "    coordinates = coord_data[['LATITUDE', 'LONGITUDE']].values.astype(float)\n",
    "    \n",
    "    # Test with k=5 nearest neighbors\n",
    "    k_neighbors = 10\n",
    "    nbrs = NearestNeighbors(n_neighbors=k_neighbors, metric='haversine')\n",
    "    \n",
    "    # Convert to radians for haversine distance (great circle distance)\n",
    "    coordinates_rad = np.radians(coordinates)\n",
    "    nbrs.fit(coordinates_rad)\n",
    "    \n",
    "    # Test BOROUGH imputation\n",
    "    borough_results = []\n",
    "    if borough_missing_count > 0:\n",
    "        print(f\"\\nðŸ™ï¸ TESTING BOROUGH IMPUTATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get sample of missing boroughs for testing (first 10)\n",
    "        missing_borough_indices = coord_data[~borough_known].index[:10]\n",
    "        \n",
    "        for idx in missing_borough_indices:\n",
    "            target_coords = coord_data.loc[idx, ['LATITUDE', 'LONGITUDE']].values.reshape(1, -1)\n",
    "            target_coords_rad = np.radians(target_coords.astype(float))\n",
    "            \n",
    "            # Find nearest neighbors\n",
    "            distances, indices = nbrs.kneighbors(target_coords_rad)\n",
    "            neighbor_indices = coord_data.iloc[indices[0]].index\n",
    "            \n",
    "            # Get boroughs from neighbors (exclude NaN values)\n",
    "            neighbor_boroughs = coord_data.loc[neighbor_indices, 'BOROUGH'].dropna()\n",
    "            \n",
    "            if len(neighbor_boroughs) > 0:\n",
    "                # Count occurrences of each borough\n",
    "                borough_counts = neighbor_boroughs.value_counts()\n",
    "                most_common_borough = borough_counts.index[0]\n",
    "                confidence = borough_counts.iloc[0] / len(neighbor_boroughs)\n",
    "                \n",
    "                # Convert distance from radians to km (approximate)\n",
    "                distances_km = distances[0] * 6371  # Earth's radius in km\n",
    "                \n",
    "                borough_results.append({\n",
    "                    'collision_id': coord_data.loc[idx, 'COLLISION_ID'],\n",
    "                    'lat': coord_data.loc[idx, 'LATITUDE'],\n",
    "                    'lon': coord_data.loc[idx, 'LONGITUDE'],\n",
    "                    'predicted_borough': most_common_borough,\n",
    "                    'confidence': confidence,\n",
    "                    'avg_distance_km': distances_km.mean(),\n",
    "                    'neighbor_boroughs': list(neighbor_boroughs.values),\n",
    "                    'neighbor_distances_km': list(distances_km)\n",
    "                })\n",
    "        \n",
    "        print(f\"ðŸ“‹ BOROUGH IMPUTATION RESULTS (first 10 examples):\")\n",
    "        for i, result in enumerate(borough_results, 1):\n",
    "            print(f\"\\n{i}. Collision ID: {result['collision_id']}\")\n",
    "            print(f\"   Coordinates: ({result['lat']:.6f}, {result['lon']:.6f})\")\n",
    "            print(f\"   Predicted Borough: {result['predicted_borough']} (confidence: {result['confidence']:.2f})\")\n",
    "            print(f\"   Average distance to neighbors: {result['avg_distance_km']:.3f} km\")\n",
    "            print(f\"   Neighbor boroughs: {result['neighbor_boroughs']}\")\n",
    "    \n",
    "    # Test ZIP CODE imputation\n",
    "    zip_results = []\n",
    "    if zip_missing_count > 0:\n",
    "        print(f\"\\nðŸ“® TESTING ZIP CODE IMPUTATION:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get sample of missing zip codes for testing (first 10)\n",
    "        missing_zip_indices = coord_data[~zip_known].index[:10]\n",
    "        \n",
    "        for idx in missing_zip_indices:\n",
    "            target_coords = coord_data.loc[idx, ['LATITUDE', 'LONGITUDE']].values.reshape(1, -1)\n",
    "            target_coords_rad = np.radians(target_coords.astype(float))\n",
    "            \n",
    "            # Find nearest neighbors\n",
    "            distances, indices = nbrs.kneighbors(target_coords_rad)\n",
    "            neighbor_indices = coord_data.iloc[indices[0]].index\n",
    "            \n",
    "            # Get zip codes from neighbors (exclude NaN values)\n",
    "            neighbor_zips = coord_data.loc[neighbor_indices, 'ZIP CODE'].dropna()\n",
    "            \n",
    "            if len(neighbor_zips) > 0:\n",
    "                # Count occurrences of each zip code\n",
    "                zip_counts = neighbor_zips.value_counts()\n",
    "                most_common_zip = zip_counts.index[0]\n",
    "                confidence = zip_counts.iloc[0] / len(neighbor_zips)\n",
    "                \n",
    "                # Convert distance from radians to km\n",
    "                distances_km = distances[0] * 6371\n",
    "                \n",
    "                zip_results.append({\n",
    "                    'collision_id': coord_data.loc[idx, 'COLLISION_ID'],\n",
    "                    'lat': coord_data.loc[idx, 'LATITUDE'],\n",
    "                    'lon': coord_data.loc[idx, 'LONGITUDE'],\n",
    "                    'predicted_zip': most_common_zip,\n",
    "                    'confidence': confidence,\n",
    "                    'avg_distance_km': distances_km.mean(),\n",
    "                    'neighbor_zips': list(neighbor_zips.values),\n",
    "                    'neighbor_distances_km': list(distances_km)\n",
    "                })\n",
    "        \n",
    "        print(f\"ðŸ“‹ ZIP CODE IMPUTATION RESULTS (first 10 examples):\")\n",
    "        for i, result in enumerate(zip_results, 1):\n",
    "            print(f\"\\n{i}. Collision ID: {result['collision_id']}\")\n",
    "            print(f\"   Coordinates: ({result['lat']:.6f}, {result['lon']:.6f})\")\n",
    "            print(f\"   Predicted ZIP: {result['predicted_zip']} (confidence: {result['confidence']:.2f})\")\n",
    "            print(f\"   Average distance to neighbors: {result['avg_distance_km']:.3f} km\")\n",
    "            print(f\"   Neighbor ZIP codes: {result['neighbor_zips']}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nðŸ“ˆ IMPUTATION QUALITY ASSESSMENT:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if borough_results:\n",
    "        avg_borough_confidence = sum(r['confidence'] for r in borough_results) / len(borough_results)\n",
    "        avg_borough_distance = sum(r['avg_distance_km'] for r in borough_results) / len(borough_results)\n",
    "        print(f\"BOROUGH Imputation:\")\n",
    "        print(f\"   â€¢ Average confidence: {avg_borough_confidence:.2f}\")\n",
    "        print(f\"   â€¢ Average distance to neighbors: {avg_borough_distance:.3f} km\")\n",
    "        print(f\"   â€¢ High confidence predictions (>0.6): {sum(1 for r in borough_results if r['confidence'] > 0.6)}/{len(borough_results)}\")\n",
    "    \n",
    "    if zip_results:\n",
    "        avg_zip_confidence = sum(r['confidence'] for r in zip_results) / len(zip_results)\n",
    "        avg_zip_distance = sum(r['avg_distance_km'] for r in zip_results) / len(zip_results)\n",
    "        print(f\"\\nZIP CODE Imputation:\")\n",
    "        print(f\"   â€¢ Average confidence: {avg_zip_confidence:.2f}\")\n",
    "        print(f\"   â€¢ Average distance to neighbors: {avg_zip_distance:.3f} km\")\n",
    "        print(f\"   â€¢ High confidence predictions (>0.6): {sum(1 for r in zip_results if r['confidence'] > 0.6)}/{len(zip_results)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "    if borough_results and avg_borough_confidence > 0.6:\n",
    "        print(f\"   âœ… BOROUGH imputation looks promising (avg confidence: {avg_borough_confidence:.2f})\")\n",
    "    elif borough_results:\n",
    "        print(f\"   âš ï¸ BOROUGH imputation has moderate confidence (avg: {avg_borough_confidence:.2f})\")\n",
    "    \n",
    "    if zip_results and avg_zip_confidence > 0.6:\n",
    "        print(f\"   âœ… ZIP CODE imputation looks promising (avg confidence: {avg_zip_confidence:.2f})\")\n",
    "    elif zip_results:\n",
    "        print(f\"   âš ï¸ ZIP CODE imputation has moderate confidence (avg: {avg_zip_confidence:.2f})\")\n",
    "    \n",
    "    print(f\"\\nðŸš€ NEXT STEPS:\")\n",
    "    print(f\"   â€¢ If results look good, we can impute all missing values\")\n",
    "    print(f\"   â€¢ Consider adjusting k={k_neighbors} neighbors based on confidence scores\")\n",
    "    print(f\"   â€¢ Set confidence threshold for imputation (e.g., only impute if confidence > 0.6)\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâœ… No missing BOROUGH or ZIP CODE values found!\")\n",
    "    print(\"All coordinates already have complete location data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dba90",
   "metadata": {},
   "source": [
    "this  show the potentiality of grouping close locations together and imputing the missing values, however it becomes infeasible using k nearest neighbours, using other datastucture such as ball tree can be more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef29b4d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:23.986541Z",
     "start_time": "2025-11-21T15:45:30.179568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ ULTRA-FAST LOCATION-BASED GROUPING IMPUTATION\n",
      "============================================================\n",
      "ðŸ“Š STARTING ANALYSIS:\n",
      "   â€¢ Total rows with coordinates: 1,972,666\n",
      "   â€¢ Missing BOROUGH: 476,174\n",
      "   â€¢ Missing ZIP CODE: 476,419\n",
      "\n",
      "ðŸŽ¯ GROUPING LOCATIONS:\n",
      "   â€¢ Coordinate precision: 5 decimal places (~1-meter accuracy)\n",
      "   â€¢ Unique location groups created: 308,213\n",
      "   â€¢ Average crashes per location: 6.4\n",
      "\n",
      "ðŸš¨ INCONSISTENCY DETECTION:\n",
      "   â€¢ Locations with multiple BOROUGHs: 373\n",
      "   â€¢ Locations with multiple ZIP CODEs: 764\n",
      "\n",
      "ðŸ“‹ BOROUGH INCONSISTENCIES (first 5):\n",
      "   1. Location (40.696033, -73.984535)\n",
      "      â€¢ 1406 crashes with boroughs: ['BROOKLYN', 'QUEENS']\n",
      "   2. Location (40.804700, -73.912430)\n",
      "      â€¢ 597 crashes with boroughs: ['BRONX', 'BROOKLYN', 'MANHATTAN']\n",
      "   3. Location (40.763110, -73.962524)\n",
      "      â€¢ 558 crashes with boroughs: ['MANHATTAN', 'QUEENS']\n",
      "   4. Location (40.770770, -73.917270)\n",
      "      â€¢ 470 crashes with boroughs: ['QUEENS', 'STATEN ISLAND']\n",
      "   5. Location (40.820305, -73.890830)\n",
      "      â€¢ 467 crashes with boroughs: ['BRONX', 'MANHATTAN']\n",
      "\n",
      "ðŸ“‹ ZIP CODE INCONSISTENCIES (first 5):\n",
      "   1. Location (40.696033, -73.984535)\n",
      "      â€¢ 1406 crashes with ZIP codes: ['11201', '11420']\n",
      "   2. Location (40.804700, -73.912430)\n",
      "      â€¢ 597 crashes with ZIP codes: ['10454', '11236', '10028']\n",
      "   3. Location (40.763110, -73.962524)\n",
      "      â€¢ 558 crashes with ZIP codes: ['10065', '11375']\n",
      "   4. Location (40.758976, -73.993940)\n",
      "      â€¢ 493 crashes with ZIP codes: ['10018', '10001']\n",
      "   5. Location (40.770770, -73.917270)\n",
      "      â€¢ 470 crashes with ZIP codes: ['11103', '10312']\n",
      "\n",
      "âš¡ VECTORIZED IMPUTATION RESULTS:\n",
      "   â€¢ Location groups with known BOROUGH: 278,340\n",
      "   â€¢ Location groups with known ZIP CODE: 278,305\n",
      "   â€¢ BOROUGH imputation: 205,779 / 476,174 values (43.2%)\n",
      "   â€¢ ZIP CODE imputation: 205,844 / 476,419 values (43.2%)\n",
      "\n",
      "â±ï¸ PERFORMANCE BREAKDOWN:\n",
      "   â€¢ Data preparation: 2.315 seconds\n",
      "   â€¢ Location grouping: 61.474 seconds\n",
      "   â€¢ Inconsistency analysis: 1.523 seconds\n",
      "   â€¢ Vectorized imputation: 1.382 seconds\n",
      "   â€¢ Total processing time: 69.005 seconds\n",
      "\n",
      "ðŸ“ˆ FINAL SUMMARY:\n",
      "   â€¢ Method: Vectorized location-based grouping (pandas .map())\n",
      "   â€¢ Precision: 5 decimal places\n",
      "   â€¢ Data quality issues detected: 373 borough conflicts, 764 ZIP conflicts\n",
      "   â€¢ Processing speed: ~5965 imputations per second\n",
      "   â€¢ Coverage: 411,623 total values imputed\n",
      "\n",
      "âœ… LOCATION-BASED IMPUTATION COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "#LOCATION-BASED GROUPING IMPUTATION with Inconsistency Detection\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "# Start timing for performance analysis\n",
    "start_time = time.time()\n",
    "\n",
    "# Get rows with coordinates\n",
    "has_coords = crashes_sample['LATITUDE'].notna() & crashes_sample['LONGITUDE'].notna()\n",
    "coord_data = crashes_sample[has_coords].copy()\n",
    "\n",
    "# Store initial stats\n",
    "initial_rows = len(coord_data)\n",
    "initial_borough_missing = coord_data['BOROUGH'].isna().sum()\n",
    "initial_zip_missing = coord_data['ZIP CODE'].isna().sum()\n",
    "\n",
    "step1_time = time.time()\n",
    "\n",
    "# Round coordinates to reasonable precision (5 decimal places = ~1 meter accuracy)\n",
    "coord_precision = 5\n",
    "coord_data['LAT_ROUNDED'] = coord_data['LATITUDE'].round(coord_precision)\n",
    "coord_data['LON_ROUNDED'] = coord_data['LONGITUDE'].round(coord_precision)\n",
    "coord_data['LOCATION_KEY'] = coord_data['LAT_ROUNDED'].astype(str) + ',' + coord_data['LON_ROUNDED'].astype(str)\n",
    "\n",
    "step2_time = time.time()\n",
    "\n",
    "# Analyze location groups using vectorized operations\n",
    "location_groups = coord_data.groupby('LOCATION_KEY').agg({\n",
    "    'COLLISION_ID': 'count',\n",
    "    'BOROUGH': lambda x: x.dropna().unique().tolist() if len(x.dropna()) > 0 else [],\n",
    "    'ZIP CODE': lambda x: x.dropna().unique().tolist() if len(x.dropna()) > 0 else [],\n",
    "    'LATITUDE': 'first',\n",
    "    'LONGITUDE': 'first'\n",
    "}).rename(columns={'COLLISION_ID': 'CRASH_COUNT'})\n",
    "\n",
    "step3_time = time.time()\n",
    "\n",
    "# Find inconsistencies\n",
    "location_groups['BOROUGH_COUNT'] = location_groups['BOROUGH'].apply(len)\n",
    "location_groups['ZIP_COUNT'] = location_groups['ZIP CODE'].apply(len)\n",
    "\n",
    "inconsistent_boroughs = location_groups[location_groups['BOROUGH_COUNT'] > 1]\n",
    "inconsistent_zips = location_groups[location_groups['ZIP_COUNT'] > 1]\n",
    "\n",
    "# Create canonical mappings\n",
    "location_groups['CANONICAL_BOROUGH'] = location_groups['BOROUGH'].apply(\n",
    "    lambda boroughs: Counter(boroughs).most_common(1)[0][0] if len(boroughs) > 0 else None\n",
    ")\n",
    "location_groups['CANONICAL_ZIP'] = location_groups['ZIP CODE'].apply(\n",
    "    lambda zips: Counter(zips).most_common(1)[0][0] if len(zips) > 0 else None\n",
    ")\n",
    "\n",
    "step4_time = time.time()\n",
    "\n",
    "# Create mapping dictionaries for fast lookup\n",
    "borough_mapping = location_groups[location_groups['CANONICAL_BOROUGH'].notna()]['CANONICAL_BOROUGH'].to_dict()\n",
    "zip_mapping = location_groups[location_groups['CANONICAL_ZIP'].notna()]['CANONICAL_ZIP'].to_dict()\n",
    "\n",
    "# ULTRA-FAST VECTORIZED IMPUTATION (no loops!)\n",
    "# Apply borough imputation using vectorized map operation\n",
    "borough_missing_mask = coord_data['BOROUGH'].isna()\n",
    "if borough_missing_mask.any():\n",
    "    # Use pandas map for vectorized lookup - much faster than loops\n",
    "    coord_data.loc[borough_missing_mask, 'BOROUGH'] = coord_data.loc[borough_missing_mask, 'LOCATION_KEY'].map(borough_mapping)\n",
    "\n",
    "# Apply zip code imputation using vectorized map operation\n",
    "zip_missing_mask = coord_data['ZIP CODE'].isna()  \n",
    "if zip_missing_mask.any():\n",
    "    # Use pandas map for vectorized lookup - much faster than loops\n",
    "    coord_data.loc[zip_missing_mask, 'ZIP CODE'] = coord_data.loc[zip_missing_mask, 'LOCATION_KEY'].map(zip_mapping)\n",
    "\n",
    "step5_time = time.time()\n",
    "\n",
    "# Count successful imputations\n",
    "borough_imputed = initial_borough_missing - coord_data['BOROUGH'].isna().sum()\n",
    "zip_imputed = initial_zip_missing - coord_data['ZIP CODE'].isna().sum()\n",
    "\n",
    "# Update main dataset using vectorized update\n",
    "crashes_sample.update(coord_data[['BOROUGH', 'ZIP CODE']])\n",
    "\n",
    "# Clean up temporary columns\n",
    "coord_data = coord_data.drop(['LAT_ROUNDED', 'LON_ROUNDED', 'LOCATION_KEY'], axis=1)\n",
    "\n",
    "final_time = time.time()\n",
    "\n",
    "# ==================== ALL PRINTS AT THE END ====================\n",
    "print(\"ðŸŽ¯ ULTRA-FAST LOCATION-BASED GROUPING IMPUTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"ðŸ“Š STARTING ANALYSIS:\")\n",
    "print(f\"   â€¢ Total rows with coordinates: {initial_rows:,}\")\n",
    "print(f\"   â€¢ Missing BOROUGH: {initial_borough_missing:,}\")\n",
    "print(f\"   â€¢ Missing ZIP CODE: {initial_zip_missing:,}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ GROUPING LOCATIONS:\")\n",
    "print(f\"   â€¢ Coordinate precision: {coord_precision} decimal places (~1-meter accuracy)\")\n",
    "print(f\"   â€¢ Unique location groups created: {len(location_groups):,}\")\n",
    "print(f\"   â€¢ Average crashes per location: {location_groups['CRASH_COUNT'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nðŸš¨ INCONSISTENCY DETECTION:\")\n",
    "print(f\"   â€¢ Locations with multiple BOROUGHs: {len(inconsistent_boroughs):,}\")\n",
    "print(f\"   â€¢ Locations with multiple ZIP CODEs: {len(inconsistent_zips):,}\")\n",
    "\n",
    "# Show examples of inconsistencies\n",
    "if len(inconsistent_boroughs) > 0:\n",
    "    print(f\"\\nðŸ“‹ BOROUGH INCONSISTENCIES (first 5):\")\n",
    "    top_borough_issues = inconsistent_boroughs.nlargest(5, 'CRASH_COUNT')\n",
    "    for idx, (location_key, row) in enumerate(top_borough_issues.iterrows(), 1):\n",
    "        print(f\"   {idx}. Location ({row['LATITUDE']:.6f}, {row['LONGITUDE']:.6f})\")\n",
    "        print(f\"      â€¢ {row['CRASH_COUNT']} crashes with boroughs: {row['BOROUGH']}\")\n",
    "\n",
    "if len(inconsistent_zips) > 0:\n",
    "    print(f\"\\nðŸ“‹ ZIP CODE INCONSISTENCIES (first 5):\")\n",
    "    top_zip_issues = inconsistent_zips.nlargest(5, 'CRASH_COUNT')\n",
    "    for idx, (location_key, row) in enumerate(top_zip_issues.iterrows(), 1):\n",
    "        print(f\"   {idx}. Location ({row['LATITUDE']:.6f}, {row['LONGITUDE']:.6f})\")\n",
    "        print(f\"      â€¢ {row['CRASH_COUNT']} crashes with ZIP codes: {row['ZIP CODE']}\")\n",
    "\n",
    "print(f\"\\nâš¡ VECTORIZED IMPUTATION RESULTS:\")\n",
    "print(f\"   â€¢ Location groups with known BOROUGH: {len(borough_mapping):,}\")\n",
    "print(f\"   â€¢ Location groups with known ZIP CODE: {len(zip_mapping):,}\")\n",
    "print(f\"   â€¢ BOROUGH imputation: {borough_imputed:,} / {initial_borough_missing:,} values ({borough_imputed/initial_borough_missing*100 if initial_borough_missing > 0 else 0:.1f}%)\")\n",
    "print(f\"   â€¢ ZIP CODE imputation: {zip_imputed:,} / {initial_zip_missing:,} values ({zip_imputed/initial_zip_missing*100 if initial_zip_missing > 0 else 0:.1f}%)\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ PERFORMANCE BREAKDOWN:\")\n",
    "print(f\"   â€¢ Data preparation: {step2_time - step1_time:.3f} seconds\")\n",
    "print(f\"   â€¢ Location grouping: {step3_time - step2_time:.3f} seconds\") \n",
    "print(f\"   â€¢ Inconsistency analysis: {step4_time - step3_time:.3f} seconds\")\n",
    "print(f\"   â€¢ Vectorized imputation: {step5_time - step4_time:.3f} seconds\")\n",
    "print(f\"   â€¢ Total processing time: {final_time - start_time:.3f} seconds\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ FINAL SUMMARY:\")\n",
    "print(f\"   â€¢ Method: Vectorized location-based grouping (pandas .map())\")\n",
    "print(f\"   â€¢ Precision: {coord_precision} decimal places\")\n",
    "print(f\"   â€¢ Data quality issues detected: {len(inconsistent_boroughs)} borough conflicts, {len(inconsistent_zips)} ZIP conflicts\") \n",
    "print(f\"   â€¢ Processing speed: ~{(borough_imputed + zip_imputed)/(final_time - start_time):.0f} imputations per second\")\n",
    "print(f\"   â€¢ Coverage: {borough_imputed + zip_imputed:,} total values imputed\")\n",
    "\n",
    "print(f\"\\nâœ… LOCATION-BASED IMPUTATION COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc3ea2",
   "metadata": {},
   "source": [
    "it might be resonable to impute streets as well, but after revising the collisions of boroughs, i suppose that imputing the street will be a complete mess and no hope of getting somthing valuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c1b9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:24.322484Z",
     "start_time": "2025-11-21T15:46:24.170516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace any missing BOROUGH with 'Unknown' and missing zip code with \"-1\"\n",
    "crashes_sample['BOROUGH'] = crashes_sample['BOROUGH'].fillna('Unknown')\n",
    "crashes_sample['ZIP CODE'] = crashes_sample['ZIP CODE'].fillna('-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcb502",
   "metadata": {},
   "source": [
    "with this we can make visuallizations clear about the zip codes of rows we aren't aware of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3342a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:25.596776Z",
     "start_time": "2025-11-21T15:46:24.326800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\n",
      "==================================================\n",
      "\n",
      "All columns with their missing value statistics:\n",
      "                       Column  Missing_Count  Missing_Percentage Data_Type\n",
      "          VEHICLE TYPE CODE 5        1963833               99.55    object\n",
      "CONTRIBUTING FACTOR VEHICLE 5        1963555               99.54    object\n",
      "          VEHICLE TYPE CODE 4        1941084               98.40    object\n",
      "CONTRIBUTING FACTOR VEHICLE 4        1939895               98.34    object\n",
      "          VEHICLE TYPE CODE 3        1836201               93.08    object\n",
      "CONTRIBUTING FACTOR VEHICLE 3        1830583               92.80    object\n",
      "              OFF STREET NAME        1611339               81.68    object\n",
      "            CROSS STREET NAME         747114               37.87    object\n",
      "               ON STREET NAME         423368               21.46    object\n",
      "          VEHICLE TYPE CODE 2         406149               20.59    object\n",
      "CONTRIBUTING FACTOR VEHICLE 2         322665               16.36    object\n",
      "          VEHICLE TYPE CODE 1          14782                0.75    object\n",
      "CONTRIBUTING FACTOR VEHICLE 1           7163                0.36    object\n",
      "     NUMBER OF PERSONS KILLED             28                0.00   float64\n",
      "    NUMBER OF PERSONS INJURED             16                0.00   float64\n",
      "                     LOCATION              0                0.00    object\n",
      "                   CRASH DATE              0                0.00    object\n",
      "                   CRASH TIME              0                0.00    object\n",
      "                      BOROUGH              0                0.00    object\n",
      "                     ZIP CODE              0                0.00    object\n",
      "                     LATITUDE              0                0.00   float64\n",
      "NUMBER OF PEDESTRIANS INJURED              0                0.00     int64\n",
      "                    LONGITUDE              0                0.00   float64\n",
      "    NUMBER OF MOTORIST KILLED              0                0.00     int64\n",
      "   NUMBER OF MOTORIST INJURED              0                0.00     int64\n",
      " NUMBER OF PEDESTRIANS KILLED              0                0.00     int64\n",
      "    NUMBER OF CYCLIST INJURED              0                0.00     int64\n",
      "     NUMBER OF CYCLIST KILLED              0                0.00     int64\n",
      "                 COLLISION_ID              0                0.00     int64\n"
     ]
    }
   ],
   "source": [
    "# Clear any previous output and create missing stats analysis\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': crashes_sample.columns,\n",
    "    'Missing_Count': crashes_sample.isnull().sum(),\n",
    "    'Missing_Percentage': (crashes_sample.isnull().sum() / len(crashes_sample) * 100).round(2),\n",
    "    'Data_Type': crashes_sample.dtypes\n",
    "})\n",
    "\n",
    "# Sort by missing count (descending)\n",
    "missing_stats = missing_stats.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Missing Values Analysis for Crashes Dataset\n",
    "print(\"ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAll columns with their missing value statistics:\")\n",
    "print(missing_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5d3b702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:25.935540Z",
     "start_time": "2025-11-21T15:46:25.785040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›£ï¸ STREET INFORMATION PATTERN ANALYSIS\n",
      "==================================================\n",
      "ðŸ”„ STREET INFORMATION PATTERNS:\n",
      "   â€¢ ON + CROSS     : 1,225,480 rows ( 62.1%)\n",
      "   â€¢ OFF only       :  361,293 rows ( 18.3%)\n",
      "   â€¢ ON only        :  323,784 rows ( 16.4%)\n",
      "   â€¢ No street info :   62,037 rows (  3.1%)\n",
      "   â€¢ CROSS only     :       38 rows (  0.0%)\n",
      "   â€¢ All three      :       34 rows (  0.0%)\n",
      "   â€¢ ON + OFF       :        0 rows (  0.0%)\n",
      "   â€¢ CROSS + OFF    :        0 rows (  0.0%)\n",
      "\n",
      "âœ… STREET PATTERN ANALYSIS COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# SIMPLE STREET INFORMATION PATTERN ANALYSIS\n",
    "print(\"ðŸ›£ï¸ STREET INFORMATION PATTERN ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check all possible combinations of street fields\n",
    "on_street = crashes_sample['ON STREET NAME'].notna()\n",
    "cross_street = crashes_sample['CROSS STREET NAME'].notna()\n",
    "off_street = crashes_sample['OFF STREET NAME'].notna()\n",
    "\n",
    "# Create pattern combinations\n",
    "patterns = {\n",
    "    'ON + CROSS': (on_street & cross_street & ~off_street).sum(),\n",
    "    'OFF only': (~on_street & ~cross_street & off_street).sum(),\n",
    "    'ON only': (on_street & ~cross_street & ~off_street).sum(),\n",
    "    'No street info': (~on_street & ~cross_street & ~off_street).sum(),\n",
    "    'CROSS only': (~on_street & cross_street & ~off_street).sum(),\n",
    "    'All three': (on_street & cross_street & off_street).sum(),\n",
    "    'ON + OFF': (on_street & ~cross_street & off_street).sum(),\n",
    "    'CROSS + OFF': (~on_street & cross_street & off_street).sum()\n",
    "}\n",
    "\n",
    "total_rows = len(crashes_sample)\n",
    "\n",
    "print(f\"ðŸ”„ STREET INFORMATION PATTERNS:\")\n",
    "# Display patterns sorted by frequency\n",
    "sorted_patterns = sorted(patterns.items(), key=lambda x: x[1], reverse=True)\n",
    "for pattern, count in sorted_patterns:\n",
    "    percentage = count / total_rows * 100\n",
    "    print(f\"   â€¢ {pattern:<15}: {count:>8,} rows ({percentage:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… STREET PATTERN ANALYSIS COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2079dc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:26.080184Z",
     "start_time": "2025-11-21T15:46:25.939540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for CONTRIBUTING FACTOR VEHICLE 1:\n",
      "CONTRIBUTING FACTOR VEHICLE 1\n",
      "Unspecified                                              656323\n",
      "Driver Inattention/Distraction                           406870\n",
      "Failure to Yield Right-of-Way                            121469\n",
      "Following Too Closely                                    102471\n",
      "Backing Unsafely                                          74151\n",
      "Other Vehicular                                           61742\n",
      "Passing or Lane Usage Improper                            57551\n",
      "Passing Too Closely                                       52767\n",
      "Turning Improperly                                        47500\n",
      "Fatigued/Drowsy                                           37889\n",
      "Unsafe Lane Changing                                      37528\n",
      "Traffic Control Disregarded                               36538\n",
      "Driver Inexperience                                       32135\n",
      "Unsafe Speed                                              30854\n",
      "Alcohol Involvement                                       22984\n",
      "Reaction to Uninvolved Vehicle                            18999\n",
      "Lost Consciousness                                        17739\n",
      "Pavement Slippery                                         17621\n",
      "View Obstructed/Limited                                   13927\n",
      "Prescription Medication                                   13059\n",
      "Oversized Vehicle                                         11663\n",
      "Outside Car Distraction                                   10894\n",
      "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion     10699\n",
      "Aggressive Driving/Road Rage                               9995\n",
      "Physical Disability                                        8031\n",
      "Passenger Distraction                                      7840\n",
      "NaN                                                        7163\n",
      "Brakes Defective                                           6477\n",
      "Fell Asleep                                                5581\n",
      "Obstruction/Debris                                         3943\n",
      "Glare                                                      3812\n",
      "Failure to Keep Right                                      3008\n",
      "Steering Failure                                           2874\n",
      "Tire Failure/Inadequate                                    2395\n",
      "Pavement Defective                                         2248\n",
      "Other Electronic Device                                    2005\n",
      "Illness                                                    1958\n",
      "Illnes                                                     1750\n",
      "Animals Action                                             1462\n",
      "Driverless/Runaway Vehicle                                 1339\n",
      "Reaction to Other Uninvolved Vehicle                       1146\n",
      "Accelerator Defective                                      1067\n",
      "Lane Marking Improper/Inadequate                            887\n",
      "Drugs (illegal)                                             885\n",
      "Traffic Control Device Improper/Non-Working                 778\n",
      "Cell Phone (hand-Held)                                      546\n",
      "Drugs (Illegal)                                             366\n",
      "Cell Phone (hands-free)                                     237\n",
      "Tow Hitch Defective                                         211\n",
      "Tinted Windows                                              187\n",
      "Other Lighting Defects                                      181\n",
      "Vehicle Vandalism                                           146\n",
      "Headlights Defective                                        137\n",
      "Using On Board Navigation Device                            134\n",
      "Eating or Drinking                                          125\n",
      "Shoulders Defective/Improper                                 89\n",
      "Windshield Inadequate                                        81\n",
      "Cell Phone (hand-held)                                       66\n",
      "80                                                           62\n",
      "Texting                                                      52\n",
      "Listening/Using Headphones                                   24\n",
      "1                                                             5\n",
      "Name: count, dtype: int64\n",
      "Size of list: 62\n",
      "\n",
      "Value counts for CONTRIBUTING FACTOR VEHICLE 2:\n",
      "CONTRIBUTING FACTOR VEHICLE 2\n",
      "Unspecified                                              1390170\n",
      "NaN                                                       322665\n",
      "Driver Inattention/Distraction                             89845\n",
      "Other Vehicular                                            30331\n",
      "Following Too Closely                                      17716\n",
      "Failure to Yield Right-of-Way                              16030\n",
      "Passing or Lane Usage Improper                             12302\n",
      "Fatigued/Drowsy                                             8579\n",
      "Passing Too Closely                                         8547\n",
      "Turning Improperly                                          7757\n",
      "Backing Unsafely                                            7282\n",
      "Traffic Control Disregarded                                 7163\n",
      "Driver Inexperience                                         6473\n",
      "Unsafe Lane Changing                                        6138\n",
      "Unsafe Speed                                                5729\n",
      "Lost Consciousness                                          4402\n",
      "Pavement Slippery                                           3644\n",
      "View Obstructed/Limited                                     3120\n",
      "Reaction to Uninvolved Vehicle                              3097\n",
      "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion       2685\n",
      "Prescription Medication                                     2552\n",
      "Outside Car Distraction                                     2189\n",
      "Oversized Vehicle                                           2106\n",
      "Physical Disability                                         1869\n",
      "Aggressive Driving/Road Rage                                1582\n",
      "Alcohol Involvement                                         1487\n",
      "Passenger Distraction                                       1395\n",
      "Obstruction/Debris                                           642\n",
      "Failure to Keep Right                                        615\n",
      "Other Electronic Device                                      550\n",
      "Lane Marking Improper/Inadequate                             470\n",
      "Traffic Control Device Improper/Non-Working                  462\n",
      "Fell Asleep                                                  425\n",
      "Glare                                                        409\n",
      "Illness                                                      394\n",
      "Brakes Defective                                             362\n",
      "Reaction to Other Uninvolved Vehicle                         314\n",
      "Pavement Defective                                           168\n",
      "Driverless/Runaway Vehicle                                    97\n",
      "Steering Failure                                              95\n",
      "Tire Failure/Inadequate                                       94\n",
      "Drugs (Illegal)                                               92\n",
      "Cell Phone (hand-Held)                                        67\n",
      "Accelerator Defective                                         65\n",
      "Headlights Defective                                          63\n",
      "Animals Action                                                62\n",
      "Other Lighting Defects                                        53\n",
      "Illnes                                                        47\n",
      "Tinted Windows                                                43\n",
      "Drugs (illegal)                                               43\n",
      "Cell Phone (hands-free)                                       42\n",
      "Tow Hitch Defective                                           32\n",
      "Cell Phone (hand-held)                                        19\n",
      "Vehicle Vandalism                                             14\n",
      "Listening/Using Headphones                                    14\n",
      "Using On Board Navigation Device                              13\n",
      "80                                                            12\n",
      "Shoulders Defective/Improper                                  12\n",
      "Eating or Drinking                                            11\n",
      "Windshield Inadequate                                          5\n",
      "Texting                                                        3\n",
      "1                                                              2\n",
      "Name: count, dtype: int64\n",
      "Size of list: 62\n",
      "\n",
      "Value counts for CONTRIBUTING FACTOR VEHICLE 3:\n",
      "CONTRIBUTING FACTOR VEHICLE 3\n",
      "NaN                                                      1830583\n",
      "Unspecified                                               132819\n",
      "Other Vehicular                                             2780\n",
      "Driver Inattention/Distraction                              1796\n",
      "Following Too Closely                                       1758\n",
      "Fatigued/Drowsy                                              633\n",
      "Pavement Slippery                                            334\n",
      "Reaction to Uninvolved Vehicle                               202\n",
      "Unsafe Speed                                                 172\n",
      "Driver Inexperience                                          170\n",
      "Outside Car Distraction                                      142\n",
      "Failure to Yield Right-of-Way                                134\n",
      "Traffic Control Disregarded                                  125\n",
      "Passing or Lane Usage Improper                               115\n",
      "Alcohol Involvement                                           98\n",
      "Backing Unsafely                                              78\n",
      "Unsafe Lane Changing                                          77\n",
      "Turning Improperly                                            68\n",
      "Obstruction/Debris                                            65\n",
      "Passing Too Closely                                           54\n",
      "Fell Asleep                                                   52\n",
      "Aggressive Driving/Road Rage                                  45\n",
      "View Obstructed/Limited                                       43\n",
      "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion         35\n",
      "Brakes Defective                                              32\n",
      "Other Electronic Device                                       31\n",
      "Lost Consciousness                                            29\n",
      "Failure to Keep Right                                         25\n",
      "Oversized Vehicle                                             19\n",
      "Prescription Medication                                       18\n",
      "Physical Disability                                           18\n",
      "Passenger Distraction                                         17\n",
      "Pavement Defective                                            16\n",
      "Traffic Control Device Improper/Non-Working                   14\n",
      "Glare                                                         10\n",
      "Driverless/Runaway Vehicle                                    10\n",
      "Tire Failure/Inadequate                                        7\n",
      "Drugs (Illegal)                                                6\n",
      "Drugs (illegal)                                                5\n",
      "Accelerator Defective                                          4\n",
      "Illness                                                        4\n",
      "Animals Action                                                 4\n",
      "Tinted Windows                                                 3\n",
      "Lane Marking Improper/Inadequate                               3\n",
      "Steering Failure                                               2\n",
      "Cell Phone (hands-free)                                        2\n",
      "Reaction to Other Uninvolved Vehicle                           2\n",
      "Eating or Drinking                                             1\n",
      "Cell Phone (hand-Held)                                         1\n",
      "Illnes                                                         1\n",
      "80                                                             1\n",
      "1                                                              1\n",
      "Vehicle Vandalism                                              1\n",
      "Tow Hitch Defective                                            1\n",
      "Name: count, dtype: int64\n",
      "Size of list: 54\n",
      "\n",
      "Value counts for CONTRIBUTING FACTOR VEHICLE 4:\n",
      "CONTRIBUTING FACTOR VEHICLE 4\n",
      "NaN                                            1939895\n",
      "Unspecified                                      30984\n",
      "Other Vehicular                                    637\n",
      "Following Too Closely                              354\n",
      "Driver Inattention/Distraction                     256\n",
      "Fatigued/Drowsy                                    126\n",
      "Pavement Slippery                                  101\n",
      "Reaction to Uninvolved Vehicle                      38\n",
      "Unsafe Speed                                        32\n",
      "Driver Inexperience                                 27\n",
      "Outside Car Distraction                             26\n",
      "Obstruction/Debris                                  20\n",
      "Alcohol Involvement                                 19\n",
      "Passing or Lane Usage Improper                      18\n",
      "Traffic Control Disregarded                         17\n",
      "Fell Asleep                                         17\n",
      "Failure to Yield Right-of-Way                       16\n",
      "Backing Unsafely                                     8\n",
      "Aggressive Driving/Road Rage                         8\n",
      "Other Electronic Device                              7\n",
      "Unsafe Lane Changing                                 6\n",
      "Failure to Keep Right                                6\n",
      "Brakes Defective                                     5\n",
      "Pavement Defective                                   5\n",
      "Passing Too Closely                                  4\n",
      "Turning Improperly                                   4\n",
      "View Obstructed/Limited                              4\n",
      "Driverless/Runaway Vehicle                           3\n",
      "Lost Consciousness                                   2\n",
      "Traffic Control Device Improper/Non-Working          2\n",
      "Tow Hitch Defective                                  2\n",
      "Physical Disability                                  2\n",
      "Tire Failure/Inadequate                              2\n",
      "Drugs (illegal)                                      2\n",
      "Drugs (Illegal)                                      2\n",
      "Passenger Distraction                                1\n",
      "Accelerator Defective                                1\n",
      "Animals Action                                       1\n",
      "Oversized Vehicle                                    1\n",
      "Illness                                              1\n",
      "Steering Failure                                     1\n",
      "Glare                                                1\n",
      "Prescription Medication                              1\n",
      "Windshield Inadequate                                1\n",
      "Name: count, dtype: int64\n",
      "Size of list: 44\n",
      "\n",
      "Value counts for CONTRIBUTING FACTOR VEHICLE 5:\n",
      "CONTRIBUTING FACTOR VEHICLE 5\n",
      "NaN                                            1963555\n",
      "Unspecified                                       8612\n",
      "Other Vehicular                                    193\n",
      "Following Too Closely                               88\n",
      "Driver Inattention/Distraction                      58\n",
      "Pavement Slippery                                   46\n",
      "Fatigued/Drowsy                                     29\n",
      "Alcohol Involvement                                 11\n",
      "Reaction to Uninvolved Vehicle                      10\n",
      "Obstruction/Debris                                  10\n",
      "Unsafe Speed                                         9\n",
      "Driver Inexperience                                  8\n",
      "Failure to Yield Right-of-Way                        5\n",
      "Outside Car Distraction                              5\n",
      "Traffic Control Disregarded                          3\n",
      "Fell Asleep                                          3\n",
      "Passing Too Closely                                  2\n",
      "Failure to Keep Right                                2\n",
      "Drugs (illegal)                                      2\n",
      "Aggressive Driving/Road Rage                         2\n",
      "Oversized Vehicle                                    1\n",
      "Pavement Defective                                   1\n",
      "Passing or Lane Usage Improper                       1\n",
      "Other Electronic Device                              1\n",
      "Tire Failure/Inadequate                              1\n",
      "Illness                                              1\n",
      "Brakes Defective                                     1\n",
      "Glare                                                1\n",
      "Steering Failure                                     1\n",
      "Backing Unsafely                                     1\n",
      "Traffic Control Device Improper/Non-Working          1\n",
      "Tow Hitch Defective                                  1\n",
      "View Obstructed/Limited                              1\n",
      "Name: count, dtype: int64\n",
      "Size of list: 33\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "for factor in ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2',\n",
    "               'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "               'CONTRIBUTING FACTOR VEHICLE 5']:\n",
    "    print(f\"\\nValue counts for {factor}:\")\n",
    "    print(crashes_sample[factor].value_counts(dropna=False))\n",
    "    print(f\"Size of list: {crashes_sample[factor].value_counts(dropna=False).size}\")\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d7938a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:26.795343Z",
     "start_time": "2025-11-21T15:46:26.084814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ CONTRIBUTING FACTOR DATA STANDARDIZATION\n",
      "============================================================\n",
      "ðŸ”§ APPLYING STANDARDIZATION...\n",
      "   â€¢ Processing CONTRIBUTING FACTOR VEHICLE 1...\n",
      "   â€¢ Processing CONTRIBUTING FACTOR VEHICLE 2...\n",
      "   â€¢ Processing CONTRIBUTING FACTOR VEHICLE 3...\n",
      "   â€¢ Processing CONTRIBUTING FACTOR VEHICLE 4...\n",
      "   â€¢ Processing CONTRIBUTING FACTOR VEHICLE 5...\n",
      "\n",
      "ðŸ“Š STANDARDIZATION RESULTS:\n",
      "--------------------------------------------------\n",
      "CONTRIBUTING FACTOR VEHICLE 1:\n",
      "   â€¢ Original categories: 62\n",
      "   â€¢ Cleaned categories: 19\n",
      "   â€¢ Reduction: 43 categories (69.4%)\n",
      "CONTRIBUTING FACTOR VEHICLE 2:\n",
      "   â€¢ Original categories: 62\n",
      "   â€¢ Cleaned categories: 19\n",
      "   â€¢ Reduction: 43 categories (69.4%)\n",
      "CONTRIBUTING FACTOR VEHICLE 3:\n",
      "   â€¢ Original categories: 54\n",
      "   â€¢ Cleaned categories: 18\n",
      "   â€¢ Reduction: 36 categories (66.7%)\n",
      "CONTRIBUTING FACTOR VEHICLE 4:\n",
      "   â€¢ Original categories: 44\n",
      "   â€¢ Cleaned categories: 14\n",
      "   â€¢ Reduction: 30 categories (68.2%)\n",
      "CONTRIBUTING FACTOR VEHICLE 5:\n",
      "   â€¢ Original categories: 33\n",
      "   â€¢ Cleaned categories: 13\n",
      "   â€¢ Reduction: 20 categories (60.6%)\n",
      "\n",
      "ðŸŽ¯ CLEANED VALUE COUNTS - CONTRIBUTING FACTOR VEHICLE 1:\n",
      "--------------------------------------------------\n",
      "CONTRIBUTING FACTOR VEHICLE 1\n",
      "Unspecified                      656323\n",
      "Driver Distraction               425604\n",
      "Driver Skill Issues              335814\n",
      "Unsafe Driving Behavior          270278\n",
      "Driver Impairment                107607\n",
      "Other Vehicular                   61742\n",
      "Environmental Conditions          44767\n",
      "Reaction to Other Vehicle         20145\n",
      "Vehicle Defects                   13610\n",
      "Oversized Vehicle                 11663\n",
      "Pedestrian/Bicyclist Error        10699\n",
      "NaN                                7163\n",
      "Electronic Device Distraction      2163\n",
      "Illness                            1750\n",
      "Other/Unspecified                  1552\n",
      "Drugs (Illegal)                     885\n",
      "Cell Phone (Hand-Held)              612\n",
      "Cell Phone (Hands-Free)             237\n",
      "Cell Phone Use                       52\n",
      "Name: count, dtype: int64\n",
      "Total unique categories: 19\n",
      "\n",
      "ðŸ“ˆ MAJOR CONTRIBUTING FACTOR CATEGORIES:\n",
      "--------------------------------------------------\n",
      "   â€¢ Unspecified                   :  656,323 ( 33.3%)\n",
      "   â€¢ Driver Distraction            :  425,604 ( 21.6%)\n",
      "   â€¢ Driver Skill Issues           :  335,814 ( 17.0%)\n",
      "   â€¢ Unsafe Driving Behavior       :  270,278 ( 13.7%)\n",
      "   â€¢ Driver Impairment             :  107,607 (  5.5%)\n",
      "   â€¢ Other Vehicular               :   61,742 (  3.1%)\n",
      "   â€¢ Environmental Conditions      :   44,767 (  2.3%)\n",
      "   â€¢ Reaction to Other Vehicle     :   20,145 (  1.0%)\n",
      "   â€¢ Vehicle Defects               :   13,610 (  0.7%)\n",
      "   â€¢ Oversized Vehicle             :   11,663 (  0.6%)\n",
      "\n",
      "âœ… CONTRIBUTING FACTOR STANDARDIZATION COMPLETE!\n",
      "   â€¢ Data quality improved through consistent naming\n",
      "   â€¢ Related factors grouped into logical categories\n",
      "   â€¢ Reduced complexity while maintaining meaning\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE CONTRIBUTING FACTOR DATA CLEANING\n",
    "print(\"ðŸ§¹ CONTRIBUTING FACTOR DATA STANDARDIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define all contributing factor columns\n",
    "factor_columns = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', \n",
    "                 'CONTRIBUTING FACTOR VEHICLE 5']\n",
    "\n",
    "# Create standardization mapping dictionary\n",
    "standardization_map = {\n",
    "    # Fix spelling/capitalization inconsistencies\n",
    "    'Illnes': 'Illness',\n",
    "    'Drugs (illegal)': 'Drugs (Illegal)',\n",
    "    'Cell Phone (hand-Held)': 'Cell Phone (Hand-Held)',\n",
    "    'Cell Phone (hand-held)': 'Cell Phone (Hand-Held)',\n",
    "    'Cell Phone (hands-free)': 'Cell Phone (Hands-Free)',\n",
    "    \n",
    "    # Group related cell phone usage\n",
    "    'Cell Phone (Hand-Held)': 'Cell Phone Use',\n",
    "    'Cell Phone (Hands-Free)': 'Cell Phone Use', \n",
    "    'Texting': 'Cell Phone Use',\n",
    "    'Using On Board Navigation Device': 'Electronic Device Distraction',\n",
    "    'Other Electronic Device': 'Electronic Device Distraction',\n",
    "    'Listening/Using Headphones': 'Electronic Device Distraction',\n",
    "    \n",
    "    # Group distraction-related factors\n",
    "    'Driver Inattention/Distraction': 'Driver Distraction',\n",
    "    'Outside Car Distraction': 'Driver Distraction',\n",
    "    'Passenger Distraction': 'Driver Distraction',\n",
    "    \n",
    "    # Group impairment factors\n",
    "    'Fatigued/Drowsy': 'Driver Impairment',\n",
    "    'Fell Asleep': 'Driver Impairment',\n",
    "    'Alcohol Involvement': 'Driver Impairment',\n",
    "    'Drugs (Illegal)': 'Driver Impairment',\n",
    "    'Prescription Medication': 'Driver Impairment',\n",
    "    'Illness': 'Driver Impairment',\n",
    "    'Lost Consciousness': 'Driver Impairment',\n",
    "    'Physical Disability': 'Driver Impairment',\n",
    "    \n",
    "    # Group driving behavior issues\n",
    "    'Aggressive Driving/Road Rage': 'Unsafe Driving Behavior',\n",
    "    'Unsafe Speed': 'Unsafe Driving Behavior',\n",
    "    'Following Too Closely': 'Unsafe Driving Behavior',\n",
    "    'Passing Too Closely': 'Unsafe Driving Behavior',\n",
    "    'Unsafe Lane Changing': 'Unsafe Driving Behavior',\n",
    "    'Traffic Control Disregarded': 'Unsafe Driving Behavior',\n",
    "    'Eating or Drinking': 'Unsafe Driving Behavior',\n",
    "    \n",
    "    # Group inexperience/skill issues\n",
    "    'Driver Inexperience': 'Driver Skill Issues',\n",
    "    'Backing Unsafely': 'Driver Skill Issues',\n",
    "    'Turning Improperly': 'Driver Skill Issues',\n",
    "    'Passing or Lane Usage Improper': 'Driver Skill Issues',\n",
    "    'Failure to Yield Right-of-Way': 'Driver Skill Issues',\n",
    "    'Failure to Keep Right': 'Driver Skill Issues',\n",
    "    \n",
    "    # Group vehicle defects\n",
    "    'Brakes Defective': 'Vehicle Defects',\n",
    "    'Steering Failure': 'Vehicle Defects',\n",
    "    'Tire Failure/Inadequate': 'Vehicle Defects',\n",
    "    'Accelerator Defective': 'Vehicle Defects',\n",
    "    'Headlights Defective': 'Vehicle Defects',\n",
    "    'Other Lighting Defects': 'Vehicle Defects',\n",
    "    'Tow Hitch Defective': 'Vehicle Defects',\n",
    "    'Windshield Inadequate': 'Vehicle Defects',\n",
    "    'Tinted Windows': 'Vehicle Defects',\n",
    "    \n",
    "    # Group environmental factors\n",
    "    'Pavement Slippery': 'Environmental Conditions',\n",
    "    'Pavement Defective': 'Environmental Conditions',\n",
    "    'View Obstructed/Limited': 'Environmental Conditions',\n",
    "    'Glare': 'Environmental Conditions',\n",
    "    'Obstruction/Debris': 'Environmental Conditions',\n",
    "    'Animals Action': 'Environmental Conditions',\n",
    "    'Lane Marking Improper/Inadequate': 'Environmental Conditions',\n",
    "    'Traffic Control Device Improper/Non-Working': 'Environmental Conditions',\n",
    "    'Shoulders Defective/Improper': 'Environmental Conditions',\n",
    "    \n",
    "    # Clean up unclear entries\n",
    "    '1': 'Other/Unspecified',\n",
    "    '80': 'Other/Unspecified',\n",
    "    'Vehicle Vandalism': 'Other/Unspecified',\n",
    "    'Driverless/Runaway Vehicle': 'Other/Unspecified',\n",
    "    \n",
    "    # Keep some specific categories as-is\n",
    "    'Oversized Vehicle': 'Oversized Vehicle',\n",
    "    'Pedestrian/Bicyclist/Other Pedestrian Error/Confusion': 'Pedestrian/Bicyclist Error',\n",
    "    'Reaction to Uninvolved Vehicle': 'Reaction to Other Vehicle',\n",
    "    'Reaction to Other Uninvolved Vehicle': 'Reaction to Other Vehicle',\n",
    "}\n",
    "\n",
    "print(\"ðŸ”§ APPLYING STANDARDIZATION...\")\n",
    "\n",
    "# Store original counts for comparison\n",
    "original_counts = {}\n",
    "for col in factor_columns:\n",
    "    if col in crashes_sample.columns:\n",
    "        original_counts[col] = crashes_sample[col].value_counts(dropna=False).shape[0]\n",
    "\n",
    "# Apply standardization to each column\n",
    "cleaned_counts = {}\n",
    "for col in factor_columns:\n",
    "    if col in crashes_sample.columns:\n",
    "        print(f\"   â€¢ Processing {col}...\")\n",
    "        \n",
    "        # Apply mapping\n",
    "        crashes_sample[col] = crashes_sample[col].map(standardization_map).fillna(crashes_sample[col])\n",
    "        \n",
    "        # Count unique values after cleaning\n",
    "        cleaned_counts[col] = crashes_sample[col].value_counts(dropna=False).shape[0]\n",
    "\n",
    "print(f\"\\nðŸ“Š STANDARDIZATION RESULTS:\")\n",
    "print(\"-\" * 50)\n",
    "for col in factor_columns:\n",
    "    if col in crashes_sample.columns:\n",
    "        original = original_counts.get(col, 0)\n",
    "        cleaned = cleaned_counts.get(col, 0)\n",
    "        reduction = original - cleaned\n",
    "        reduction_pct = (reduction / original * 100) if original > 0 else 0\n",
    "        \n",
    "        print(f\"{col}:\")\n",
    "        print(f\"   â€¢ Original categories: {original}\")\n",
    "        print(f\"   â€¢ Cleaned categories: {cleaned}\")\n",
    "        print(f\"   â€¢ Reduction: {reduction} categories ({reduction_pct:.1f}%)\")\n",
    "\n",
    "# Show the cleaned value counts for CONTRIBUTING FACTOR VEHICLE 1\n",
    "print(f\"\\nðŸŽ¯ CLEANED VALUE COUNTS - CONTRIBUTING FACTOR VEHICLE 1:\")\n",
    "print(\"-\" * 50)\n",
    "cleaned_vc = crashes_sample['CONTRIBUTING FACTOR VEHICLE 1'].value_counts(dropna=False)\n",
    "print(cleaned_vc)\n",
    "print(f\"Total unique categories: {len(cleaned_vc)}\")\n",
    "\n",
    "# Summary of major category groups\n",
    "print(f\"\\nðŸ“ˆ MAJOR CONTRIBUTING FACTOR CATEGORIES:\")\n",
    "print(\"-\" * 50)\n",
    "major_categories = cleaned_vc.head(10)\n",
    "for category, count in major_categories.items():\n",
    "    percentage = count / len(crashes_sample) * 100\n",
    "    print(f\"   â€¢ {category:<30}: {count:>8,} ({percentage:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nâœ… CONTRIBUTING FACTOR STANDARDIZATION COMPLETE!\")\n",
    "print(f\"   â€¢ Data quality improved through consistent naming\")\n",
    "print(f\"   â€¢ Related factors grouped into logical categories\")\n",
    "print(f\"   â€¢ Reduced complexity while maintaining meaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384adb16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:27.278348Z",
     "start_time": "2025-11-21T15:46:26.799891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After standardization - Contributing Factor Analysis\n",
      "============================================================\n",
      "\n",
      "CONTRIBUTING FACTOR VEHICLE 1:\n",
      "  Unique values: 18\n",
      "  Top 10 values:\n",
      "    Unspecified: 656,323 (33.27%)\n",
      "    Driver Distraction: 425,604 (21.58%)\n",
      "    Driver Skill Issues: 335,814 (17.02%)\n",
      "    Unsafe Driving Behavior: 270,278 (13.70%)\n",
      "    Driver Impairment: 107,607 (5.45%)\n",
      "    Other Vehicular: 61,742 (3.13%)\n",
      "    Environmental Conditions: 44,767 (2.27%)\n",
      "    Reaction to Other Vehicle: 20,145 (1.02%)\n",
      "    Vehicle Defects: 13,610 (0.69%)\n",
      "    Oversized Vehicle: 11,663 (0.59%)\n",
      "\n",
      "CONTRIBUTING FACTOR VEHICLE 2:\n",
      "  Unique values: 18\n",
      "  Top 10 values:\n",
      "    Unspecified: 1,390,170 (70.47%)\n",
      "    Driver Distraction: 93,429 (4.74%)\n",
      "    Driver Skill Issues: 50,459 (2.56%)\n",
      "    Unsafe Driving Behavior: 46,886 (2.38%)\n",
      "    Other Vehicular: 30,331 (1.54%)\n",
      "    Driver Impairment: 19,800 (1.00%)\n",
      "    Environmental Conditions: 8,989 (0.46%)\n",
      "    Reaction to Other Vehicle: 3,411 (0.17%)\n",
      "    Pedestrian/Bicyclist Error: 2,685 (0.14%)\n",
      "    Oversized Vehicle: 2,106 (0.11%)\n",
      "\n",
      "CONTRIBUTING FACTOR VEHICLE 3:\n",
      "  Unique values: 17\n",
      "  Top 10 values:\n",
      "    Unspecified: 132,819 (6.73%)\n",
      "    Other Vehicular: 2,780 (0.14%)\n",
      "    Unsafe Driving Behavior: 2,232 (0.11%)\n",
      "    Driver Distraction: 1,955 (0.10%)\n",
      "    Driver Impairment: 858 (0.04%)\n",
      "    Driver Skill Issues: 590 (0.03%)\n",
      "    Environmental Conditions: 489 (0.02%)\n",
      "    Reaction to Other Vehicle: 204 (0.01%)\n",
      "    Vehicle Defects: 49 (0.00%)\n",
      "    Pedestrian/Bicyclist Error: 35 (0.00%)\n",
      "\n",
      "CONTRIBUTING FACTOR VEHICLE 4:\n",
      "  Unique values: 13\n",
      "  Top 10 values:\n",
      "    Unspecified: 30,984 (1.57%)\n",
      "    Other Vehicular: 637 (0.03%)\n",
      "    Unsafe Driving Behavior: 421 (0.02%)\n",
      "    Driver Distraction: 283 (0.01%)\n",
      "    Driver Impairment: 170 (0.01%)\n",
      "    Environmental Conditions: 134 (0.01%)\n",
      "    Driver Skill Issues: 79 (0.00%)\n",
      "    Reaction to Other Vehicle: 38 (0.00%)\n",
      "    Vehicle Defects: 12 (0.00%)\n",
      "    Electronic Device Distraction: 7 (0.00%)\n",
      "\n",
      "CONTRIBUTING FACTOR VEHICLE 5:\n",
      "  Unique values: 12\n",
      "  Top 10 values:\n",
      "    Unspecified: 8,612 (0.44%)\n",
      "    Other Vehicular: 193 (0.01%)\n",
      "    Unsafe Driving Behavior: 104 (0.01%)\n",
      "    Driver Distraction: 63 (0.00%)\n",
      "    Environmental Conditions: 60 (0.00%)\n",
      "    Driver Impairment: 44 (0.00%)\n",
      "    Driver Skill Issues: 17 (0.00%)\n",
      "    Reaction to Other Vehicle: 10 (0.00%)\n",
      "    Vehicle Defects: 4 (0.00%)\n",
      "    Drugs (Illegal): 2 (0.00%)\n",
      "\n",
      "============================================================\n",
      "STANDARDIZATION SUMMARY\n",
      "============================================================\n",
      "   Factor Total Records       Unspecified         Specified\n",
      "VEHICLE 1     1,972,666   656,323 (33.3%) 1,316,343 (66.7%)\n",
      "VEHICLE 2     1,972,666 1,390,170 (70.5%)   582,496 (29.5%)\n",
      "VEHICLE 3     1,972,666    132,819 (6.7%) 1,839,847 (93.3%)\n",
      "VEHICLE 4     1,972,666     30,984 (1.6%) 1,941,682 (98.4%)\n",
      "VEHICLE 5     1,972,666      8,612 (0.4%) 1,964,054 (99.6%)\n",
      "\n",
      "Total collision records processed: 1,972,666\n",
      "All contributing factors now have consistent, standardized values!\n"
     ]
    }
   ],
   "source": [
    "# Let's see the dramatic improvement in data consistency\n",
    "print(\"After standardization - Contributing Factor Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check each factor column\n",
    "for col in factor_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {crashes_sample[col].nunique()}\")\n",
    "    print(f\"  Top 10 values:\")\n",
    "    top_values = crashes_sample[col].value_counts().head(10)\n",
    "    for value, count in top_values.items():\n",
    "        percentage = (count / len(crashes_sample)) * 100\n",
    "        print(f\"    {value}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "# Summary of the standardization\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STANDARDIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count records with standardized values (not Unspecified)\n",
    "factor_data = []\n",
    "for col in factor_columns:\n",
    "    total = len(crashes_sample)\n",
    "    unspecified = (crashes_sample[col] == 'Unspecified').sum()\n",
    "    specified = total - unspecified\n",
    "    factor_data.append({\n",
    "        'Factor': col.replace('CONTRIBUTING FACTOR ', ''),\n",
    "        'Total Records': f\"{total:,}\",\n",
    "        'Unspecified': f\"{unspecified:,} ({(unspecified/total)*100:.1f}%)\",\n",
    "        'Specified': f\"{specified:,} ({(specified/total)*100:.1f}%)\"\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame(factor_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal collision records processed: {len(crashes_sample):,}\")\n",
    "print(f\"All contributing factors now have consistent, standardized values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2860c609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:46:31.031800Z",
     "start_time": "2025-11-21T15:46:27.282677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Created 'CRASH DATETIME' column by combining 'CRASH DATE' and 'CRASH TIME'\n",
      "   Sample values:\n",
      "2023-11-01 01:29:00\n",
      "2021-09-11 09:35:00\n",
      "2021-12-14 08:13:00\n"
     ]
    }
   ],
   "source": [
    "# Convert CRASH DATE(datetime[ns64]) and CRASH TIME(str) to datetime\n",
    "crashes_sample['CRASH DATETIME'] = pd.to_datetime(\n",
    "    crashes_sample['CRASH DATE'].astype(str) + ' ' + crashes_sample['CRASH TIME'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "# Drop original columns\n",
    "crashes_sample = crashes_sample.drop(columns=['CRASH DATE', 'CRASH TIME'])\n",
    "\n",
    "print(\"\\nâœ“ Created 'CRASH DATETIME' column by combining 'CRASH DATE' and 'CRASH TIME'\")\n",
    "print(f\"   Sample values:\\n{crashes_sample['CRASH DATETIME'].head(3).to_string(index=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80e887c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Filled missing street information strategically\n",
      "   â€¢ Moved OFF STREET to ON STREET where appropriate\n",
      "   â€¢ Filled remaining gaps with descriptive defaults\n"
     ]
    }
   ],
   "source": [
    "# Fill missing street information strategically\n",
    "# For rows with OFF STREET only, fill ON STREET with OFF STREET value\n",
    "off_only_mask = (crashes_sample['ON STREET NAME'].isna() & \n",
    "                 crashes_sample['CROSS STREET NAME'].isna() & \n",
    "                 crashes_sample['OFF STREET NAME'].notna())\n",
    "crashes_sample.loc[off_only_mask, 'ON STREET NAME'] = crashes_sample.loc[off_only_mask, 'OFF STREET NAME']\n",
    "\n",
    "# Fill remaining missing values\n",
    "crashes_sample['ON STREET NAME'] = crashes_sample['ON STREET NAME'].fillna('Unknown Street')\n",
    "crashes_sample['CROSS STREET NAME'] = crashes_sample['CROSS STREET NAME'].fillna('No Cross Street')\n",
    "crashes_sample['OFF STREET NAME'] = crashes_sample['OFF STREET NAME'].fillna('No Off Street')\n",
    "\n",
    "print(f\"âœ“ Filled missing street information strategically\")\n",
    "print(f\"   â€¢ Moved OFF STREET to ON STREET where appropriate\")\n",
    "print(f\"   â€¢ Filled remaining gaps with descriptive defaults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adcb31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Filled missing values in all vehicle type code columns with 'Unknown'\n"
     ]
    }
   ],
   "source": [
    "# Fill missing vehicle type codes with 'Unknown'\n",
    "vehicle_type_columns = ['VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', \n",
    "                       'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', \n",
    "                       'VEHICLE TYPE CODE 5']\n",
    "\n",
    "for col in vehicle_type_columns:\n",
    "    crashes_sample[col] = crashes_sample[col].fillna('Unknown')\n",
    "\n",
    "print(f\"âœ“ Filled missing values in all vehicle type code columns with 'Unknown'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f1dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Filled missing values in 'NUMBER OF PERSONS INJURED' and 'NUMBER OF PERSONS KILLED' using component sums\n"
     ]
    }
   ],
   "source": [
    "# Fill Number of Persons Injured and Number of Persons Killed missing values \n",
    "# with sum of PEDESTRIANS, CYCLISTS, MOTORISTS injured/killed\n",
    "injured_columns = ['NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF CYCLIST INJURED', 'NUMBER OF MOTORIST INJURED']\n",
    "killed_columns = ['NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED']\n",
    "crashes_sample['NUMBER OF PERSONS INJURED'] = crashes_sample['NUMBER OF PERSONS INJURED'].fillna(\n",
    "    crashes_sample[injured_columns].sum(axis=1)\n",
    ")\n",
    "crashes_sample['NUMBER OF PERSONS KILLED'] = crashes_sample['NUMBER OF PERSONS KILLED'].fillna(\n",
    "    crashes_sample[killed_columns].sum(axis=1)\n",
    ")\n",
    "print(f\"âœ“ Filled missing values in 'NUMBER OF PERSONS INJURED' and 'NUMBER OF PERSONS KILLED' using component sums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99f4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\n",
      "==================================================\n",
      "\n",
      "All columns with their missing value statistics:\n",
      "                       Column  Missing_Count  Missing_Percentage      Data_Type\n",
      "CONTRIBUTING FACTOR VEHICLE 5        1963555               99.54         object\n",
      "CONTRIBUTING FACTOR VEHICLE 4        1939895               98.34         object\n",
      "CONTRIBUTING FACTOR VEHICLE 3        1830583               92.80         object\n",
      "CONTRIBUTING FACTOR VEHICLE 2         322665               16.36         object\n",
      "CONTRIBUTING FACTOR VEHICLE 1           7163                0.36         object\n",
      "                     LOCATION              0                0.00         object\n",
      "            CROSS STREET NAME              0                0.00         object\n",
      "               ON STREET NAME              0                0.00         object\n",
      "                      BOROUGH              0                0.00         object\n",
      "                     ZIP CODE              0                0.00         object\n",
      "                     LATITUDE              0                0.00        float64\n",
      "                    LONGITUDE              0                0.00        float64\n",
      " NUMBER OF PEDESTRIANS KILLED              0                0.00          int64\n",
      "NUMBER OF PEDESTRIANS INJURED              0                0.00          int64\n",
      "     NUMBER OF PERSONS KILLED              0                0.00        float64\n",
      "    NUMBER OF PERSONS INJURED              0                0.00        float64\n",
      "              OFF STREET NAME              0                0.00         object\n",
      "    NUMBER OF MOTORIST KILLED              0                0.00          int64\n",
      "     NUMBER OF CYCLIST KILLED              0                0.00          int64\n",
      "   NUMBER OF MOTORIST INJURED              0                0.00          int64\n",
      "    NUMBER OF CYCLIST INJURED              0                0.00          int64\n",
      "                 COLLISION_ID              0                0.00          int64\n",
      "          VEHICLE TYPE CODE 1              0                0.00         object\n",
      "          VEHICLE TYPE CODE 2              0                0.00         object\n",
      "          VEHICLE TYPE CODE 3              0                0.00         object\n",
      "          VEHICLE TYPE CODE 4              0                0.00         object\n",
      "          VEHICLE TYPE CODE 5              0                0.00         object\n",
      "               CRASH DATETIME              0                0.00 datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Clear any previous output and create missing stats analysis\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': crashes_sample.columns,\n",
    "    'Missing_Count': crashes_sample.isnull().sum(),\n",
    "    'Missing_Percentage': (crashes_sample.isnull().sum() / len(crashes_sample) * 100).round(2),\n",
    "    'Data_Type': crashes_sample.dtypes\n",
    "})\n",
    "\n",
    "# Sort by missing count (descending)\n",
    "missing_stats = missing_stats.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Missing Values Analysis for Crashes Dataset\n",
    "print(\"ðŸ” MISSING VALUES ANALYSIS - CRASHES DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAll columns with their missing value statistics:\")\n",
    "print(missing_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84e14c487efd5542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:49:03.439522Z",
     "start_time": "2025-11-21T15:48:50.685830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CLEANED DATA SAVED: data_cleaned/nyc_vehicle_crashes_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = 'data_cleaned/nyc_vehicle_crashes_cleaned.csv'\n",
    "crashes_sample.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"\\n CLEANED DATA SAVED: {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
